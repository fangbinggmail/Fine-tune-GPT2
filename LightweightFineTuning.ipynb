{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "Load pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f115fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#tokenizer.pad_token = tokenizer.\n",
    "\n",
    "print(tokenizer.model_max_length)  # Check the maximum length of the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb13a68",
   "metadata": {},
   "source": [
    "### Load the Dataset\n",
    "\n",
    "Choose some prompts. Then evaluate the model generated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe65aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 4500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the finance instruction dataset\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "# ds = load_dataset(\"Josephgflowers/Finance-Instruct-500k\", split=\"train[:5000]\")\n",
    "\n",
    "# Just read the first 5000 entries only due to resource limits\n",
    "# ds = load_dataset(\"talkmap/banking-conversation-corpus\", split=\"train[:5000]\")\n",
    "\n",
    "# ds = load_dataset(\"KidzRizal/twitter-sentiment-analysis\", split=\"train[:5000]\")\n",
    "\n",
    "dataset_name = \"AiresPucrs/sentiment-analysis\"\n",
    "ds = load_dataset(dataset_name, split=\"train[:5000]\")\n",
    "\n",
    "# split into train and test sets\n",
    "ds = ds.train_test_split(test_size=0.1)\n",
    "# explore the dataset\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f29f1e",
   "metadata": {},
   "source": [
    "### Quickly check the model\n",
    "\n",
    "Use the first 10 texts from the test set to check how the model perform\n",
    "> The same set of prompts will be used before and after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a2dbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "8531caec-c658-4e58-acff-a4f2bb50d445",
       "rows": [
        [
         "1",
         "the magnificent greta garbo is in top form in this her first talkie she gets fine support from the rest of the cast which includes charles bickford the rugged sailor who captures her heart ms garbo gives a great performance as she usually does as the estranged daughter of a sea captain who returns after fifteen years also in the cast is that great actress marie dressler a great movie!",
         "1"
        ],
        [
         "20",
         "cates is insipid and unconvincing kline over acts as always as does lithgow while butchering an english accent at least i assume that's what he's attempting and the tone staggers uneasily between farcical and maudlin as with most pet projects showcasing a celebrity couple it's a relief when this shoddy piece grinds to it's forced and jarring conclusion ",
         "0"
        ],
        [
         "23",
         "thriller is the greatest music video of all time !!!!! performed by the greatest artist of all time ! thriller really sent music videos going and other artists have been trying to copy thriller in one way or another ever since ! it's a thriller !!!!!!",
         "1"
        ],
        [
         "24",
         "sorry to go against the flow but i thought this film was unrealistic boring and way too long i got tired of watching gena rowlands long arduous battle with herself and the crisis she was experiencing maybe the film has some cinematic value or represented an important step for the director but for pure entertainment value i wish i would have skipped it ",
         "0"
        ],
        [
         "25",
         "i found this movie to be a simple yet wonderful comedy this movie is purely entertaining i can watch it time and time again and still enjoy the dialog and chemistry between the characters i truly hope for a dvd release!",
         "1"
        ],
        [
         "28",
         "worst dcom i have seen ever well maybe not as bad as smart house this was just bad the acting and story was fine but the effects sucked! they were so fake! the only good fight scene was between the brother and shen that was probably the only scene in which i was excited overall i found this movie very boring and the film kind of ended suddenly i will give it a four for brenda song who is a very funny actress and that one fight scene 4 10",
         "0"
        ],
        [
         "33",
         "michael is king this film contains some of the best stuff mike has ever done smooth criminal is pure genius the cameos are wonderful but as always the main event is mj himself he is the best hands down ",
         "1"
        ],
        [
         "37",
         "guy pearce almost looks like flynn and this resemblance is the only one this film can claim nowhere in flynn's autobiography is the klaus reicher character mention the homosexual encounter is speculative fiction and the movie's claims that flynn treated native labor badly are groundless director frank howson hasn't made any memorable films and i find it lame for him to groundlessly slander flynn to further his unremarkable career ",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the magnificent greta garbo is in top form in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cates is insipid and unconvincing kline over a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>thriller is the greatest music video of all ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sorry to go against the flow but i thought thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>i found this movie to be a simple yet wonderfu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>worst dcom i have seen ever well maybe not as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>michael is king this film contains some of the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>guy pearce almost looks like flynn and this re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "1   the magnificent greta garbo is in top form in ...      1\n",
       "20  cates is insipid and unconvincing kline over a...      0\n",
       "23  thriller is the greatest music video of all ti...      1\n",
       "24  sorry to go against the flow but i thought thi...      0\n",
       "25  i found this movie to be a simple yet wonderfu...      1\n",
       "28  worst dcom i have seen ever well maybe not as ...      0\n",
       "33  michael is king this film contains some of the...      1\n",
       "37  guy pearce almost looks like flynn and this re...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df = ds['test'].to_pandas()\n",
    "check_df = check_df.loc[check_df['text'].str.len() < 512][:8]\n",
    "check_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30115109",
   "metadata": {},
   "source": [
    "Check the model before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f693d73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.5052009224891663}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5264928340911865}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5301784873008728}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5146786570549011}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5180830359458923}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5140610933303833}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5085684657096863}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5569984912872314}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "orig_classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Quickly check the model\n",
    "for prompt in check_df['text'].tolist():\n",
    "    print(orig_classifier(prompt, truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cca1ee",
   "metadata": {},
   "source": [
    "**Before training**, the model seems simply picks *POSITIVE*. This is expected according to the warning message. It needs to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941fa05",
   "metadata": {},
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d47ef7",
   "metadata": {},
   "source": [
    "#### Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60940912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[0.2005, 0.0361]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# quick check that things are working\n",
    "\n",
    "inputs = tokenizer(ds['train'][0]['text'], max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "inputs['input_ids'].shape\n",
    "#print(tokenizer.decode(inputs['input_ids']))\n",
    "outputs = model(**inputs)  # Forward pass with the tokenized inputs\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396449e",
   "metadata": {},
   "source": [
    "Define a function to group the *tokenized* text into smaller (block size 128) chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75727e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer function\n",
    "def tokenize_func(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        # return_tensors=\"pt\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52eba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4500/4500 [00:00<00:00, 9660.96 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 9227.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Do the simple tokenization first and drop the un-used features.\n",
    "\n",
    "tokenized_datasets = {}\n",
    "for split in ds.keys():\n",
    "    tokenized_datasets[split] = ds[split].map(\n",
    "        tokenize_func,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456d4ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 4500\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "     num_rows: 500\n",
       " })}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4391fa",
   "metadata": {},
   "source": [
    "### Define the compute metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be30c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a compute metric function\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    # Convert logits to predictions\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"precision\": precision_score(y_true=labels, y_pred=predictions, average=\"weighted\"),\n",
    "        \"recall\": recall_score(y_true=labels, y_pred=predictions, average=\"weighted\"),\n",
    "        \"f1\": f1_score(y_true=labels, y_pred=predictions, average=\"weighted\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faea7ff",
   "metadata": {},
   "source": [
    "### Evaluate the base model using the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7238a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110289/748985022.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 01:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7026612162590027, 'eval_model_preparation_time': 0.0012, 'eval_precision': 0.46263948497854074, 'eval_recall': 0.482, 'eval_f1': 0.3644460991147514, 'eval_runtime': 95.7588, 'eval_samples_per_second': 5.221, 'eval_steps_per_second': 0.658}\n"
     ]
    }
   ],
   "source": [
    "# define the training arguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/base_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./data/logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "base_results = trainer.evaluate()\n",
    "print(base_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d7da1",
   "metadata": {},
   "source": [
    "### Setup PEFT for LORA Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "622b4bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,450 || all params: 109,780,228 || trainable%: 0.2700\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=8,\n",
    "    #lora_alpha=32,\n",
    "    #lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, config)\n",
    "lora_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91eb4c",
   "metadata": {},
   "source": [
    "#### Set the training Arguments and the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db1246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "save_path = \"./data/lora-finetuned-sentiment-analysis\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=save_path,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e47944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# let the data_collator handle the batching jobs\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a865c8",
   "metadata": {},
   "source": [
    "#### Now train the model. Without GPU, this will take a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f32ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1126' max='1126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1126/1126 1:48:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.709700</td>\n",
       "      <td>0.690214</td>\n",
       "      <td>0.550119</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.519664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.687738</td>\n",
       "      <td>0.583362</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.525589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1126, training_loss=0.6983768745171663, metrics={'train_runtime': 6503.1135, 'train_samples_per_second': 1.384, 'train_steps_per_second': 0.173, 'total_flos': 2107817639208960.0, 'train_loss': 0.6983768745171663, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a8045c",
   "metadata": {},
   "source": [
    "#### Evaluate the trainer **After** training completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 07:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6877377033233643, 'eval_precision': 0.5833615837484636, 'eval_recall': 0.556, 'eval_f1': 0.5255887306691166, 'eval_runtime': 97.5221, 'eval_samples_per_second': 5.127, 'eval_steps_per_second': 0.646, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned model\n",
    "from transformers import pipeline\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f1c7e",
   "metadata": {},
   "source": [
    "#### Check the response for the same set of prompts after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58de7f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.5196443200111389}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5295662879943848}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5149076581001282}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5009469389915466}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5080550909042358}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5076899528503418}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5017227530479431}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5228018760681152}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "new_clfr = pipeline(\"sentiment-analysis\", model=lora_model, tokenizer=tokenizer)\n",
    "\n",
    "for prompt in check_df['text'].tolist():\n",
    "    print(new_clfr(prompt, truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  Save the PEFT Tuned model to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/lora-finetuned-sentiment-analysis/tokenizer_config.json',\n",
       " './data/lora-finetuned-sentiment-analysis/special_tokens_map.json',\n",
       " './data/lora-finetuned-sentiment-analysis/vocab.txt',\n",
       " './data/lora-finetuned-sentiment-analysis/added_tokens.json',\n",
       " './data/lora-finetuned-sentiment-analysis/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "from peft import PeftConfig\n",
    "\n",
    "# save_path = \"./data/lora-finetuned-sentiment-analysis\" # (already defined above)\n",
    "lora_model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a Saved PEFT Model\n",
    "\n",
    "In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.5196443200111389}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5295662879943848}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5149076581001282}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5009469389915466}]\n",
      "[{'label': 'POSITIVE', 'score': 0.5080550909042358}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5076899528503418}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5017227530479431}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.5228018760681152}]\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned AutoPeftModelForSequenceClassification model for inference\n",
    "# save_path = \"./data/lora-finetuned-sentiment-analysis\" # (already defined above)\n",
    "# Load the fine-tuned model for inference\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig, AutoPeftModelForSequenceClassification\n",
    "\n",
    "loaded_lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    save_path,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "\n",
    "new_clfr = pipeline(\"sentiment-analysis\", model=loaded_lora_model, tokenizer=tokenizer)\n",
    "\n",
    "for prompt in check_df['text'].tolist():\n",
    "    print(new_clfr(prompt, truncation=True, max_length=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76ab70",
   "metadata": {},
   "source": [
    "### Evaluate the model just loaded from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a20378c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6877377033233643, 'eval_precision': 0.5833615837484636, 'eval_recall': 0.556, 'eval_f1': 0.5255887306691166, 'eval_runtime': 94.6162, 'eval_samples_per_second': 5.285, 'eval_steps_per_second': 0.666, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.model = loaded_lora_model\n",
    "print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a8147",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The fine-tuned model does a better job than the original model as the additional training\n",
    "dataset added more infomation to the original model. The precision/recall/F1 scores improvements\n",
    "are visible but relatively small. If the whole dataset is used in the training, the improvement \n",
    "would be more.\n",
    "\n",
    "The lodel loaded from disk has the same performance as the LORA model right after training completed\n",
    "as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d448e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
