{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f115fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "orig_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(tokenizer.model_max_length)  # Check the maximum length of the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb13a68",
   "metadata": {},
   "source": [
    "Choose some prompts. Then evaluate the model generated responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: I need to open a checking account\n",
      "[{'generated_text': \"I need to open a checking account, and I can't find out why. We have this in mind.\\n\\n\\nThe following is an example of how to do this.\\nFirst, you have to create a log.logger.logger.logger.logger.logger.logger. In this case, you have to create a new log.logger.logger.logger.logger.logger.logger. In this case, you have to create a log.logger.logger.logger.logger.logger.logger.logger.logger.log.logger.log.log.logger.log.logger.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log.log\"}]\n",
      "Prompt: I want to apply for a credit card\n",
      "[{'generated_text': 'I want to apply for a credit card.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]\n",
      "Prompt: I want to transfer money to my savings account\n",
      "[{'generated_text': 'I want to transfer money to my savings account,\\u2009 so I will have to take care of that.‚Äù'}]\n",
      "Prompt: I need to setup automatic payments for my utilities\n",
      "[{'generated_text': 'I need to setup automatic payments for my utilities and have the same address.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"I need to open a checking account\",\n",
    "    \"I want to apply for a credit card\",\n",
    "    \"I want to transfer money to my savings account\",\n",
    "    \"I need to setup automatic payments for my utilities\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(orig_generator(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa719b5",
   "metadata": {},
   "source": [
    "## Prepare the PEFT Model and Dataset for Training\n",
    "\n",
    "Setup the model for PEFT lora training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a2dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 73,728 || all params: 81,986,304 || trainable%: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "config = LoraConfig(\n",
    "    r=4,  # To reduce the number of trainable parameters\n",
    ")\n",
    "lora_model = get_peft_model(model, config)\n",
    "lora_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941fa05",
   "metadata": {},
   "source": [
    "### Load the Dataset and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['conversation_id', 'speaker', 'date_time', 'text'],\n",
      "        num_rows: 4500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['conversation_id', 'speaker', 'date_time', 'text'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the finance instruction dataset\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "# ds = load_dataset(\"Josephgflowers/Finance-Instruct-500k\", split=\"train[:5000]\")\n",
    "\n",
    "# Just read the first 5000 entries only due to resource limits\n",
    "ds = load_dataset(\"talkmap/banking-conversation-corpus\", split=\"train[:5000]\")\n",
    "\n",
    "# split into train and test sets\n",
    "ds = ds.train_test_split(test_size=0.1)\n",
    "# explore the dataset\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d47ef7",
   "metadata": {},
   "source": [
    "#### Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60940912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[-33.1717, -31.6326, -33.7443,  ..., -44.9420, -44.7888, -33.9273],\n",
       "         [-67.7578, -67.2971, -67.5085,  ..., -73.7265, -72.1330, -66.4876],\n",
       "         [-55.9518, -56.5346, -58.7248,  ..., -64.3963, -62.8929, -57.7981],\n",
       "         ...,\n",
       "         [-73.1146, -74.6174, -76.4408,  ..., -79.0709, -80.8036, -73.2944],\n",
       "         [-79.6601, -83.9914, -87.3437,  ..., -92.5419, -94.3485, -83.1136],\n",
       "         [-72.7861, -72.3935, -73.0458,  ..., -81.6174, -83.1252, -66.5091]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-8.7863e-01,  2.6339e+00,  7.7920e-01,  ..., -1.2441e+00,\n",
       "           -1.5730e-01,  1.6261e+00],\n",
       "          [-1.6237e+00,  2.7957e+00,  1.6042e+00,  ..., -9.6159e-01,\n",
       "           -1.8298e+00,  2.1775e+00],\n",
       "          [-2.1820e+00,  2.4550e+00,  1.8944e+00,  ..., -1.0605e+00,\n",
       "           -2.0144e+00,  1.5937e+00],\n",
       "          ...,\n",
       "          [-1.9662e+00,  2.5642e+00,  2.4126e+00,  ..., -1.7261e+00,\n",
       "           -2.0987e+00,  1.3006e+00],\n",
       "          [-2.2921e+00,  2.1554e+00,  8.7376e-01,  ..., -6.1927e-02,\n",
       "           -1.5977e+00,  2.5311e+00],\n",
       "          [-2.1337e+00,  2.1069e+00,  2.1244e+00,  ..., -1.3573e+00,\n",
       "           -2.4383e+00,  1.2568e+00]],\n",
       "\n",
       "         [[-2.2551e-01, -7.2276e-01, -9.8828e-01,  ...,  5.3089e-01,\n",
       "            2.5781e+00,  6.0669e-01],\n",
       "          [ 2.8080e-01, -1.3310e+00, -2.4527e+00,  ..., -1.9182e+00,\n",
       "            1.8183e+00, -9.6798e-02],\n",
       "          [-3.7158e-01, -7.6080e-01, -2.5298e+00,  ..., -3.0796e-01,\n",
       "            4.4981e+00, -2.5473e-02],\n",
       "          ...,\n",
       "          [-4.0732e-01, -2.7737e+00, -6.5669e-01,  ..., -2.7325e+00,\n",
       "            4.0472e+00, -2.7455e-01],\n",
       "          [-1.8639e+00, -2.4031e-01,  4.1195e-01,  ...,  1.8414e+00,\n",
       "            5.7398e+00, -1.2156e+00],\n",
       "          [-4.8868e-01, -9.8567e-01,  1.1571e+00,  ..., -1.4700e+00,\n",
       "            1.4606e+00,  4.7404e-01]],\n",
       "\n",
       "         [[ 4.2013e-01, -7.6825e-01,  1.0565e+00,  ..., -8.8606e-01,\n",
       "           -1.4859e+00,  5.1611e-01],\n",
       "          [ 6.6224e-01, -6.5073e-01,  6.6291e-01,  ..., -1.4158e+00,\n",
       "            7.9831e-01,  6.0066e-01],\n",
       "          [ 1.1511e-01, -3.2837e-02,  1.0998e+00,  ..., -2.3291e+00,\n",
       "            4.1538e-01,  4.4156e-01],\n",
       "          ...,\n",
       "          [ 2.5135e-01,  2.9258e-01, -5.5789e-01,  ..., -3.0556e+00,\n",
       "            1.3756e+00,  1.4876e+00],\n",
       "          [ 7.5250e-01,  2.3979e+00, -1.3913e-01,  ..., -2.6930e+00,\n",
       "            2.0932e+00,  1.1458e+00],\n",
       "          [ 6.2335e-01,  1.0780e+00,  6.7256e-01,  ..., -1.5822e+00,\n",
       "            2.0128e+00,  1.5899e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.1963e-01, -2.4097e-01, -2.4810e-01,  ...,  7.6032e-01,\n",
       "            8.8875e-01,  4.9449e-01],\n",
       "          [-1.0875e-01,  5.4113e-02,  2.2879e-01,  ...,  1.2680e+00,\n",
       "            1.6758e-01,  3.4558e-01],\n",
       "          [ 1.3561e-01,  4.9274e-02, -1.3642e-01,  ...,  1.3575e+00,\n",
       "            2.9425e-01,  4.1105e-02],\n",
       "          ...,\n",
       "          [-3.2471e-01, -3.7631e-02,  7.9208e-02,  ...,  1.3759e+00,\n",
       "            4.6815e-01,  9.5998e-02],\n",
       "          [-1.5187e-01, -5.5019e-01,  6.9740e-01,  ...,  1.1641e+00,\n",
       "            3.5175e-01,  1.0109e-01],\n",
       "          [-2.4434e-01, -3.1199e-01,  5.7235e-01,  ...,  1.2035e+00,\n",
       "            3.0506e-01,  3.1189e-01]],\n",
       "\n",
       "         [[ 5.5104e-01,  4.1646e-01,  1.1192e-01,  ..., -2.3929e-01,\n",
       "            1.1521e+00, -1.0815e+00],\n",
       "          [ 9.5377e-01,  4.7055e-01, -5.1863e-01,  ..., -8.4450e-01,\n",
       "            9.0574e-01, -8.5068e-01],\n",
       "          [ 1.5288e+00,  9.7529e-01, -2.5300e-01,  ..., -5.9990e-01,\n",
       "            7.0302e-01, -7.0974e-01],\n",
       "          ...,\n",
       "          [ 1.4496e+00, -4.2901e-01, -7.1053e-01,  ..., -4.3023e-01,\n",
       "            3.2009e-02,  1.9345e+00],\n",
       "          [ 7.5251e-01, -6.8736e-01,  6.8433e-02,  ...,  2.0785e-01,\n",
       "           -1.1137e+00,  8.5084e-01],\n",
       "          [ 6.9218e-01, -1.1243e+00, -4.5566e-01,  ..., -5.5469e-03,\n",
       "           -1.0157e-01,  1.6738e+00]],\n",
       "\n",
       "         [[ 6.3228e-01, -3.1180e-01, -2.8209e-01,  ...,  8.5131e-02,\n",
       "            6.5196e-01,  1.7442e+00],\n",
       "          [-4.5103e-01,  1.3422e-01,  7.2307e-02,  ...,  5.9397e-01,\n",
       "            5.4310e-01,  8.1680e-01],\n",
       "          [-4.6034e-01,  4.6791e-03, -1.0452e-01,  ...,  1.8654e-01,\n",
       "            1.0499e+00,  1.5406e+00],\n",
       "          ...,\n",
       "          [-7.4441e-02,  1.5027e+00, -9.5239e-01,  ..., -1.0311e+00,\n",
       "            7.0886e-01, -8.3460e-01],\n",
       "          [-1.9620e-01,  1.5323e+00, -1.0740e+00,  ..., -8.4042e-01,\n",
       "            4.2988e-01, -1.0807e+00],\n",
       "          [-9.5567e-02,  1.8478e+00, -1.8875e-02,  ..., -1.3130e+00,\n",
       "            2.3513e-01, -1.0281e+00]]]], grad_fn=<TransposeBackward0>), tensor([[[[ 7.9913e-02,  2.2958e-01, -1.8642e-02,  ...,  3.8772e-02,\n",
       "           -1.0141e-01, -7.5724e-02],\n",
       "          [-1.0794e-01,  6.6268e-02, -1.9953e-01,  ..., -1.0250e-01,\n",
       "            1.1345e-01,  1.3578e-01],\n",
       "          [ 2.0580e-01,  1.3670e-01,  8.0335e-02,  ...,  3.0703e-01,\n",
       "           -2.0732e-02, -1.7712e-01],\n",
       "          ...,\n",
       "          [ 9.6421e-02,  3.0548e-01,  9.5282e-03,  ...,  3.4160e-01,\n",
       "           -2.4879e-01, -3.9872e-02],\n",
       "          [ 1.9750e-01,  2.0488e-03,  9.3655e-02,  ..., -9.3979e-02,\n",
       "           -2.6913e-01, -1.3434e-01],\n",
       "          [ 4.7026e-02,  3.9951e-01, -8.6637e-02,  ..., -4.8680e-02,\n",
       "           -1.5642e-01, -1.8361e-02]],\n",
       "\n",
       "         [[ 1.4012e-01,  8.5244e-02,  1.9063e-02,  ..., -4.9048e-01,\n",
       "           -3.2500e-01,  1.6196e-01],\n",
       "          [ 3.2744e-01,  1.0414e-01,  1.6537e-01,  ...,  1.1418e-01,\n",
       "            3.3843e-01, -2.1845e-01],\n",
       "          [ 2.9947e-01,  6.9585e-02, -6.0192e-02,  ..., -1.5781e-01,\n",
       "            1.8608e-01,  4.9855e-02],\n",
       "          ...,\n",
       "          [-3.3812e-01,  2.3168e-03,  8.9171e-02,  ..., -1.4374e-01,\n",
       "            2.5603e-01,  1.7371e-01],\n",
       "          [-1.8544e-01, -3.0531e-02,  1.1503e-01,  ...,  1.4684e-01,\n",
       "           -2.5991e-02, -1.0176e-01],\n",
       "          [-3.4505e-01,  1.2011e-02,  1.1223e-01,  ..., -1.8281e-01,\n",
       "            5.2757e-01, -1.5447e-01]],\n",
       "\n",
       "         [[ 2.4595e-01,  5.1217e-02,  2.0800e-02,  ...,  1.3389e-01,\n",
       "           -3.2071e-02,  1.8185e-01],\n",
       "          [-2.7616e-01,  1.0318e-01, -8.8039e-02,  ...,  1.2934e-01,\n",
       "            5.3275e-02,  9.8535e-02],\n",
       "          [-4.3276e-01,  1.4248e-02, -2.9531e-02,  ...,  3.6725e-02,\n",
       "            1.5428e-01,  2.6212e-02],\n",
       "          ...,\n",
       "          [-4.5695e-01,  4.9128e-02, -5.5813e-01,  ..., -3.0869e-01,\n",
       "           -3.3689e-01, -1.3519e-01],\n",
       "          [ 6.9943e-02, -2.0006e-02, -3.6606e-01,  ...,  3.3388e-01,\n",
       "            3.0010e-02,  1.7304e-01],\n",
       "          [-4.9635e-01,  1.1169e-01, -1.6717e-01,  ..., -7.8122e-02,\n",
       "           -1.8864e-01,  2.8219e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9119e-02,  3.4402e-02,  9.1850e-02,  ...,  5.8646e-02,\n",
       "            1.6751e-01, -1.8306e-01],\n",
       "          [-3.8160e-01,  1.7122e-02,  1.1122e-01,  ..., -1.2324e-01,\n",
       "           -1.9462e-01,  9.2061e-02],\n",
       "          [-9.5357e-02, -1.2831e-01,  2.1545e-01,  ...,  2.6367e-01,\n",
       "           -1.2986e-01,  2.0563e-01],\n",
       "          ...,\n",
       "          [ 6.8737e-02,  2.0856e-01,  4.0340e-01,  ..., -1.4045e-01,\n",
       "           -3.1194e-01, -2.1290e-01],\n",
       "          [-8.2188e-03,  2.8911e-01, -8.6137e-02,  ...,  4.1422e-02,\n",
       "            1.5663e-01, -6.8751e-02],\n",
       "          [-1.2572e-01,  2.8435e-01,  7.5321e-02,  ..., -1.7749e-01,\n",
       "           -3.7475e-01,  2.1593e-02]],\n",
       "\n",
       "         [[ 6.4463e-02,  2.3065e-02, -1.5517e-01,  ...,  1.6932e-01,\n",
       "           -7.0133e-02, -6.1425e-02],\n",
       "          [-3.0733e-01, -1.1467e-02,  8.7853e-02,  ...,  6.6204e-02,\n",
       "           -5.3096e-03,  3.9803e-04],\n",
       "          [-4.2783e-01,  2.0680e-02,  1.6315e-01,  ...,  4.8472e-02,\n",
       "           -1.8990e-01, -1.5726e-01],\n",
       "          ...,\n",
       "          [-4.2922e-01,  9.2588e-02,  1.8281e-01,  ..., -3.2813e-02,\n",
       "           -3.3414e-02, -1.4400e-01],\n",
       "          [-1.3904e-01,  2.6724e-01,  6.3252e-02,  ..., -4.0312e-02,\n",
       "           -1.7130e-01,  1.1216e-01],\n",
       "          [-2.5780e-01,  2.0554e-01,  1.7349e-01,  ..., -2.2405e-01,\n",
       "            1.3326e-01, -2.2368e-01]],\n",
       "\n",
       "         [[-3.3824e-02, -9.4091e-02, -1.8808e-02,  ..., -3.8303e-02,\n",
       "           -1.5574e-01,  2.8238e-02],\n",
       "          [ 2.5927e-01, -2.8044e-01, -1.4340e-01,  ...,  1.6286e-01,\n",
       "            2.0587e-01,  1.4052e-01],\n",
       "          [-1.8177e-01,  2.6613e-01, -1.8903e-01,  ...,  3.3029e-02,\n",
       "           -9.7927e-03, -6.2138e-02],\n",
       "          ...,\n",
       "          [-3.6980e-01, -4.8402e-02, -2.1452e-01,  ...,  3.7790e-02,\n",
       "           -2.2041e-02, -3.0244e-02],\n",
       "          [-4.3077e-01,  2.8290e-02, -1.8619e-01,  ..., -1.8432e-02,\n",
       "           -3.3488e-01, -2.4342e-01],\n",
       "          [ 6.9063e-02, -3.3890e-02, -3.1214e-02,  ..., -5.6653e-02,\n",
       "            3.1021e-02, -3.8919e-01]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 4.9154e-02, -1.0925e+00,  4.1750e-01,  ..., -9.7397e-01,\n",
       "            1.4280e-01,  4.3182e-02],\n",
       "          [ 1.4047e-01, -3.6145e+00, -2.2370e-01,  ..., -4.6785e-01,\n",
       "           -7.5974e-01, -5.1312e-01],\n",
       "          [-1.7315e-01, -2.6201e+00, -6.4041e-01,  ..., -4.6079e-01,\n",
       "           -4.9172e-01, -5.3693e-01],\n",
       "          ...,\n",
       "          [-3.2400e-01,  4.9281e-01,  6.3295e-01,  ...,  1.5499e+00,\n",
       "           -4.6547e-01, -1.0043e+00],\n",
       "          [-1.0511e-01, -7.2302e-01, -1.1593e+00,  ..., -6.2470e-01,\n",
       "            2.5416e-01,  2.4778e-01],\n",
       "          [-3.8180e-01, -1.1021e+00,  1.5454e-01,  ...,  2.4192e+00,\n",
       "           -3.5152e-01, -1.0009e-01]],\n",
       "\n",
       "         [[-7.0177e-01, -1.8695e-01, -6.4067e-01,  ...,  9.0142e-01,\n",
       "           -7.7377e-01, -8.3409e-01],\n",
       "          [-7.2637e-02, -5.6024e-01, -8.0010e-01,  ...,  1.0495e-01,\n",
       "            8.9723e-01,  9.8779e-02],\n",
       "          [-5.2430e-01, -8.1058e-01, -1.2949e-01,  ..., -5.4485e-01,\n",
       "            6.6420e-01, -1.7704e-01],\n",
       "          ...,\n",
       "          [-1.2983e+00, -1.4028e+00, -4.0263e-01,  ..., -1.3592e+00,\n",
       "            1.5076e+00,  3.0586e-03],\n",
       "          [-2.4043e-01, -4.0342e-01, -9.8990e-01,  ..., -1.7625e+00,\n",
       "            4.1870e-01,  2.3307e-01],\n",
       "          [-9.8413e-01, -9.3946e-01, -1.3034e+00,  ..., -1.1718e+00,\n",
       "            2.4949e+00, -4.4255e-01]],\n",
       "\n",
       "         [[ 1.3868e+00,  2.2371e+00,  3.5367e+00,  ...,  9.0695e-01,\n",
       "            1.5626e+00, -1.0751e+00],\n",
       "          [-2.5208e+00,  4.0851e+00, -1.7086e+00,  ..., -5.9993e-01,\n",
       "            2.4016e+00, -1.0750e+00],\n",
       "          [-1.5432e+00,  3.9479e+00, -1.7444e+00,  ..., -1.3407e+00,\n",
       "            1.6522e+00, -7.5189e-01],\n",
       "          ...,\n",
       "          [-2.9913e+00, -4.6390e+00, -2.3216e+00,  ..., -2.1095e+00,\n",
       "            7.0493e-01,  4.0623e+00],\n",
       "          [-2.9479e+00, -4.5636e+00, -1.6627e+00,  ..., -4.0899e+00,\n",
       "            7.1507e-02,  3.2012e+00],\n",
       "          [-1.6093e+00, -4.9313e+00, -2.0029e+00,  ..., -2.8022e+00,\n",
       "            8.3513e-02,  2.4070e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.8588e+00, -2.1840e+00, -2.5345e+00,  ...,  9.8985e-01,\n",
       "            6.8686e-01,  2.3383e+00],\n",
       "          [-1.7811e+00, -9.3950e-01, -3.9050e+00,  ...,  1.6537e-01,\n",
       "           -3.2559e+00,  3.2368e+00],\n",
       "          [-1.7770e+00, -1.4606e+00, -2.3099e+00,  ...,  1.4288e-01,\n",
       "           -3.3549e+00,  3.1638e+00],\n",
       "          ...,\n",
       "          [-4.2791e+00,  3.4724e+00,  4.4007e+00,  ..., -1.1331e+00,\n",
       "           -5.4312e+00, -4.7144e+00],\n",
       "          [-5.5994e+00,  3.4366e+00,  3.9344e+00,  ..., -1.7798e+00,\n",
       "           -4.6461e+00, -3.8339e+00],\n",
       "          [-4.7914e+00,  3.7178e+00,  3.5088e+00,  ..., -4.5068e-01,\n",
       "           -3.2847e+00, -3.3294e+00]],\n",
       "\n",
       "         [[ 1.8657e+00,  4.1357e-01,  9.1124e-01,  ..., -2.7776e-01,\n",
       "           -1.1460e+00,  6.1096e-02],\n",
       "          [ 1.5919e+00,  7.9220e-01,  1.8204e+00,  ...,  4.8645e-01,\n",
       "           -3.7434e+00, -1.2536e+00],\n",
       "          [ 5.9598e-01,  1.0321e+00,  1.6289e+00,  ...,  1.7913e-01,\n",
       "           -2.0068e+00, -1.9554e+00],\n",
       "          ...,\n",
       "          [ 1.1070e+00, -8.3481e-02,  4.8752e-01,  ...,  3.4079e-01,\n",
       "           -1.4320e+00, -3.6743e-01],\n",
       "          [ 1.8624e+00, -4.7666e-01,  5.8238e-01,  ...,  4.5922e-01,\n",
       "           -1.1581e+00, -9.8249e-01],\n",
       "          [ 1.3814e+00,  8.5138e-01, -2.2280e-01,  ...,  1.7788e-01,\n",
       "           -1.9491e+00, -1.6385e-01]],\n",
       "\n",
       "         [[ 7.0412e-02,  2.1550e-01, -7.0437e-01,  ...,  1.8010e-01,\n",
       "            5.1597e-01,  2.0247e-01],\n",
       "          [-6.8758e-02,  8.7452e-01,  4.8684e-02,  ..., -4.3023e-01,\n",
       "            1.0181e+00, -1.0499e-01],\n",
       "          [ 5.3794e-01,  2.9242e-01, -8.2349e-01,  ..., -2.0131e+00,\n",
       "            4.4243e-01, -5.3974e-01],\n",
       "          ...,\n",
       "          [ 8.6108e-01, -3.7376e-01, -1.4532e+00,  ..., -6.1480e-02,\n",
       "            5.1140e-01,  4.1844e-01],\n",
       "          [ 1.6322e-01,  6.2641e-01, -6.6654e-01,  ...,  3.4949e-01,\n",
       "            4.9489e-01,  7.1542e-01],\n",
       "          [-8.3044e-01,  1.1025e-01, -9.4711e-01,  ...,  7.9189e-01,\n",
       "            7.0604e-01,  1.6754e+00]]]], grad_fn=<TransposeBackward0>), tensor([[[[-9.7445e-02, -8.0039e-02, -9.2061e-02,  ..., -5.6257e-04,\n",
       "           -9.4054e-02, -3.6047e-01],\n",
       "          [-1.1635e-02,  2.1916e-01, -2.4154e-01,  ...,  6.1594e-01,\n",
       "           -6.2803e-01,  7.7706e-01],\n",
       "          [ 5.3490e-01,  1.7833e-01,  1.6952e-01,  ...,  2.8176e-01,\n",
       "           -2.6853e-02,  9.3159e-01],\n",
       "          ...,\n",
       "          [ 5.4177e-01,  7.4670e-01,  6.1616e-02,  ..., -2.7695e-02,\n",
       "            3.2410e-01,  1.0855e+00],\n",
       "          [ 5.9672e-01, -1.4825e+00,  6.9181e-01,  ..., -2.9316e-01,\n",
       "            1.2836e-01,  1.0363e-01],\n",
       "          [ 1.2574e-02,  1.3022e+00, -1.5279e+00,  ...,  5.2851e-01,\n",
       "            5.0431e-01, -6.7274e-01]],\n",
       "\n",
       "         [[ 1.2034e-01,  5.7991e-02, -2.5904e-01,  ..., -6.2107e-02,\n",
       "            1.3996e-01, -1.8680e-01],\n",
       "          [-2.3340e-01, -6.1093e-02,  9.4103e-02,  ..., -4.9632e-02,\n",
       "            1.4250e-02, -3.9282e-01],\n",
       "          [-1.7553e-01,  1.3195e-01,  3.3749e-02,  ..., -1.1589e-01,\n",
       "           -3.6376e-01, -3.3925e-01],\n",
       "          ...,\n",
       "          [ 1.2744e+00,  1.1056e+00,  6.3270e-01,  ..., -1.0664e-01,\n",
       "            6.0536e-02,  3.5400e-01],\n",
       "          [ 1.3461e+00,  1.4692e+00, -4.6388e-01,  ..., -1.7019e-01,\n",
       "            9.0873e-01,  6.8083e-01],\n",
       "          [ 3.8166e-01,  9.3930e-01, -4.3165e-01,  ...,  8.0190e-02,\n",
       "           -2.0307e-03, -1.0605e+00]],\n",
       "\n",
       "         [[ 2.4412e-03, -6.7267e-01,  9.8651e-02,  ..., -8.4236e-02,\n",
       "            6.2679e-02,  3.7585e-02],\n",
       "          [-2.0322e-02, -1.0534e+00,  3.0821e-01,  ..., -7.3790e-02,\n",
       "           -4.3082e-01, -9.8498e-02],\n",
       "          [-6.3201e-01, -5.9051e-01, -2.0636e-01,  ...,  5.7917e-01,\n",
       "            2.2360e-01,  1.7666e-01],\n",
       "          ...,\n",
       "          [-2.3333e-01, -1.0526e+00,  2.1148e-01,  ...,  1.8677e-01,\n",
       "           -6.8398e-02,  2.1662e-01],\n",
       "          [ 3.1173e-01, -1.0612e+00, -1.9661e-01,  ...,  1.5625e-01,\n",
       "           -1.5829e-01, -4.3159e-01],\n",
       "          [ 4.5380e-01, -1.0259e+00,  1.6447e-01,  ..., -3.5842e-01,\n",
       "           -2.9583e-02,  1.7090e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.0787e-02, -7.3796e-02,  6.4337e-01,  ..., -1.3855e-01,\n",
       "            3.7673e-02,  4.0292e-02],\n",
       "          [-5.3239e-01, -3.6887e-01,  1.7756e+00,  ..., -4.6796e-01,\n",
       "            1.3430e-01, -3.6126e-01],\n",
       "          [ 1.3293e+00,  4.1394e-01,  7.9166e-01,  ...,  3.0273e-01,\n",
       "            3.1493e-01, -2.4730e-01],\n",
       "          ...,\n",
       "          [-2.1908e-02,  4.6994e-01,  1.0484e+00,  ..., -3.0074e-01,\n",
       "            1.0784e-03,  2.3902e-01],\n",
       "          [ 1.9568e-01, -4.0266e-01, -5.3631e-02,  ...,  2.6920e-01,\n",
       "            3.2981e-01,  1.1255e+00],\n",
       "          [ 7.9311e-02, -6.1112e-01,  1.0284e+00,  ...,  2.3471e-01,\n",
       "            2.4466e-02,  2.1515e-01]],\n",
       "\n",
       "         [[ 7.4882e-02, -1.1784e-01, -2.8351e-01,  ...,  1.9641e-03,\n",
       "           -1.7994e-01, -1.6044e-02],\n",
       "          [-1.6572e-01,  1.5248e+00,  7.2323e-01,  ..., -1.1021e+00,\n",
       "           -1.1561e+00, -4.6192e-01],\n",
       "          [ 1.8670e-01,  6.1464e-01, -3.1325e-01,  ..., -6.5819e-01,\n",
       "           -2.6825e-01,  2.2219e-02],\n",
       "          ...,\n",
       "          [ 3.2371e-02,  2.4263e-01, -1.8457e-01,  ..., -4.7916e-01,\n",
       "            1.9249e-01,  5.6783e-01],\n",
       "          [ 2.5807e-01,  2.8478e-01,  5.6029e-01,  ...,  7.0425e-03,\n",
       "           -2.8652e-01, -3.4440e-01],\n",
       "          [ 8.2999e-01,  4.0031e-01,  5.8390e-01,  ..., -4.3367e-01,\n",
       "           -6.8722e-01,  6.0497e-01]],\n",
       "\n",
       "         [[-1.6486e-02,  1.1647e-01,  4.0166e-03,  ...,  6.2351e-02,\n",
       "           -9.2324e-02,  5.0733e-03],\n",
       "          [ 3.1145e-01, -8.4050e-02,  8.3054e-01,  ..., -6.3550e-01,\n",
       "           -5.6602e-01,  4.4370e-01],\n",
       "          [-1.1674e+00, -2.6256e-01,  1.8441e-01,  ..., -1.0486e-01,\n",
       "           -1.0650e+00,  1.9627e-01],\n",
       "          ...,\n",
       "          [-3.6143e-01,  1.2745e-01, -1.5720e-01,  ..., -1.3885e-02,\n",
       "           -2.1156e+00, -6.1930e-01],\n",
       "          [ 7.2078e-01,  7.8237e-01, -2.7440e-02,  ..., -7.5496e-01,\n",
       "           -1.9472e+00, -8.7207e-01],\n",
       "          [ 4.0250e-01,  6.8669e-02,  1.0490e-01,  ...,  8.2809e-03,\n",
       "           -1.6299e+00, -2.1922e-01]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[-9.5317e-01, -1.2531e-01,  2.8869e-01,  ..., -9.3080e-01,\n",
       "            1.3001e-01, -2.7447e+00],\n",
       "          [ 1.0881e+00, -4.9698e-01, -1.4512e+00,  ..., -1.8480e+00,\n",
       "           -1.4430e+00,  2.1264e+00],\n",
       "          [ 3.9038e-01,  6.0105e-01, -1.8887e+00,  ..., -2.0689e+00,\n",
       "           -2.6872e+00,  3.7546e+00],\n",
       "          ...,\n",
       "          [ 2.4177e-02, -1.1722e-01, -4.8397e-01,  ...,  1.3252e+00,\n",
       "           -8.9719e-01,  9.4361e+00],\n",
       "          [ 8.7012e-01, -4.7329e-01, -1.0605e+00,  ...,  1.6561e+00,\n",
       "            1.2016e+00,  8.0611e+00],\n",
       "          [ 3.0784e-02, -4.8208e-01, -1.8521e+00,  ..., -3.3228e-01,\n",
       "            2.4611e-01,  7.0415e+00]],\n",
       "\n",
       "         [[ 2.6405e-01, -9.2001e-02,  5.2197e-01,  ..., -9.7601e-02,\n",
       "           -2.1893e-01, -2.0194e+00],\n",
       "          [-2.0698e+00, -1.2986e+00,  3.4684e+00,  ..., -1.0661e+00,\n",
       "           -4.7856e-01,  4.5731e+00],\n",
       "          [-4.1617e-01, -1.4084e+00,  3.4293e+00,  ..., -2.7424e+00,\n",
       "           -8.4178e-01,  6.7473e+00],\n",
       "          ...,\n",
       "          [-1.9638e+00,  1.3970e+00, -2.4028e-01,  ...,  8.4433e-01,\n",
       "            1.3380e+00,  4.2096e+00],\n",
       "          [-2.7602e+00,  9.4109e-01,  1.1173e+00,  ..., -1.0499e+00,\n",
       "            1.1541e+00,  2.7855e+00],\n",
       "          [-8.6401e-01,  1.0466e+00,  1.0535e+00,  ...,  4.1825e-01,\n",
       "            8.7498e-01,  3.1516e+00]],\n",
       "\n",
       "         [[ 1.2161e-01, -5.4690e-01, -1.6339e-01,  ...,  7.9261e-02,\n",
       "            1.8389e-01, -1.0555e-01],\n",
       "          [-6.0131e-02,  1.8039e+00,  3.6197e-01,  ..., -2.0583e-01,\n",
       "           -4.1293e-01,  5.0602e-01],\n",
       "          [-3.5688e-01,  1.5365e+00,  4.0638e-01,  ...,  8.0654e-01,\n",
       "           -7.3367e-01, -2.0531e-01],\n",
       "          ...,\n",
       "          [-1.1659e-01,  1.1285e+00,  4.5054e-02,  ..., -1.3945e+00,\n",
       "           -1.3253e+00,  8.1908e-01],\n",
       "          [ 1.0192e+00,  8.9513e-01,  5.4756e-01,  ...,  6.3464e-01,\n",
       "            9.0500e-01,  4.3667e-01],\n",
       "          [ 1.9555e-01,  2.8556e+00,  2.0502e+00,  ..., -1.9356e+00,\n",
       "            4.4152e-01,  5.2546e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5981e-01, -6.5385e-02,  8.4621e-02,  ...,  1.3054e+00,\n",
       "            1.5783e-01,  1.7685e+00],\n",
       "          [ 5.7021e-01, -4.6827e-01, -8.5313e-01,  ..., -7.5814e-01,\n",
       "           -7.7789e-01, -2.9808e-01],\n",
       "          [ 9.0783e-02, -1.0846e+00,  7.0575e-01,  ..., -7.6711e-01,\n",
       "           -3.4406e-01, -8.0515e-01],\n",
       "          ...,\n",
       "          [ 1.4173e+00,  2.2438e+00, -3.3941e-01,  ..., -2.0466e+00,\n",
       "            5.8864e-01, -1.4387e+00],\n",
       "          [ 1.1814e+00,  3.1858e+00, -5.5987e-01,  ..., -2.0588e+00,\n",
       "            4.3713e-01, -9.5206e-01],\n",
       "          [-6.3106e-01,  8.8787e-01, -1.8292e+00,  ..., -2.1412e+00,\n",
       "           -2.6147e-01, -5.2415e-01]],\n",
       "\n",
       "         [[-3.1574e-01, -1.2436e-01,  9.6747e-02,  ...,  1.3625e-01,\n",
       "           -1.3312e-02, -2.8043e-03],\n",
       "          [-9.8010e-01, -1.0902e+00,  6.5359e-01,  ...,  1.1825e+00,\n",
       "           -7.7034e-01,  1.1966e+00],\n",
       "          [-2.6831e-01, -2.1271e-01, -6.5486e-02,  ...,  1.0972e+00,\n",
       "           -5.4008e-01,  6.3005e-01],\n",
       "          ...,\n",
       "          [-3.9521e-01,  1.4220e+00,  6.3863e-01,  ...,  9.6768e-01,\n",
       "            2.3907e+00, -3.0508e-01],\n",
       "          [-1.0211e+00, -6.5245e-01,  2.3405e-01,  ...,  7.4214e-02,\n",
       "            6.0475e-01, -1.3106e+00],\n",
       "          [-2.2679e-01,  3.0638e-01,  1.3161e+00,  ...,  9.2263e-02,\n",
       "           -8.0356e-01,  5.0691e-01]],\n",
       "\n",
       "         [[ 3.3149e+00,  1.1901e+00, -2.5197e+00,  ..., -2.6200e+00,\n",
       "           -4.1072e+00, -1.4425e+00],\n",
       "          [ 5.1180e-01, -2.4146e+00,  2.3867e+00,  ..., -4.5998e+00,\n",
       "            2.5464e+00, -3.8254e+00],\n",
       "          [-1.9422e+00, -6.5885e-01,  2.2313e+00,  ..., -4.5456e+00,\n",
       "            4.5798e+00,  5.4977e-01],\n",
       "          ...,\n",
       "          [-5.0974e+00, -1.7538e+00,  7.1930e+00,  ...,  5.4483e+00,\n",
       "            1.2420e+01,  2.8522e+00],\n",
       "          [-2.1355e+00, -3.7417e+00,  9.8199e+00,  ...,  6.4420e+00,\n",
       "            8.7477e+00,  1.3137e+00],\n",
       "          [-3.4223e+00, -1.3106e+00,  9.7051e+00,  ...,  9.2551e+00,\n",
       "            8.7410e+00, -4.2868e+00]]]], grad_fn=<TransposeBackward0>), tensor([[[[ 3.6130e-02,  9.3576e-04, -8.0345e-03,  ...,  5.1512e-02,\n",
       "           -5.4239e-02,  4.6504e-02],\n",
       "          [ 3.3456e-01,  5.7446e-02,  1.2345e-01,  ..., -1.4547e-01,\n",
       "            2.3653e-01, -9.3453e-02],\n",
       "          [-2.9769e-01, -4.6523e-01, -1.5702e-01,  ..., -2.9422e-01,\n",
       "           -1.6841e-01,  1.6635e-01],\n",
       "          ...,\n",
       "          [-3.8292e-01, -1.2958e-01, -8.9347e-03,  ...,  2.9764e-01,\n",
       "            8.8326e-02,  4.0889e-01],\n",
       "          [-3.0749e-01,  3.7605e-01, -1.0240e-01,  ..., -3.3613e-01,\n",
       "           -2.3609e-01, -3.0308e-01],\n",
       "          [-9.2789e-01,  9.6690e-01,  3.0389e-02,  ...,  5.7731e-01,\n",
       "           -3.2021e-01, -1.3310e-01]],\n",
       "\n",
       "         [[-5.8543e-02,  4.6821e-02, -1.8926e-01,  ..., -1.3593e-02,\n",
       "           -2.3997e-04,  5.0147e-02],\n",
       "          [ 3.1808e-01, -1.5260e-01, -2.3155e-01,  ...,  2.1829e-01,\n",
       "           -6.6779e-02, -7.2085e-02],\n",
       "          [ 1.4536e-01,  7.6329e-01,  3.6938e-01,  ...,  4.2493e-01,\n",
       "           -3.1960e-01,  5.0931e-02],\n",
       "          ...,\n",
       "          [-3.3146e-01,  2.9388e-01,  3.1620e-01,  ...,  3.1059e-01,\n",
       "           -4.6473e-01,  1.0406e-01],\n",
       "          [-8.8808e-01,  6.2545e-01, -1.6801e-01,  ...,  4.6809e-01,\n",
       "            1.8693e-01, -1.6291e-01],\n",
       "          [-4.7340e-01, -2.3720e-01,  3.4374e-01,  ..., -2.0936e-01,\n",
       "           -4.0927e-01,  5.0483e-01]],\n",
       "\n",
       "         [[-2.1983e-02,  4.4708e-02, -1.7326e-02,  ..., -7.4636e-05,\n",
       "           -9.2203e-03,  2.5338e-02],\n",
       "          [-1.3606e-01,  1.8852e-01, -1.5692e-02,  ..., -3.9645e-01,\n",
       "           -8.1326e-01, -6.0261e-01],\n",
       "          [-7.2264e-01, -1.8543e-01, -1.2245e-01,  ..., -1.6813e-01,\n",
       "           -4.6227e-01, -2.5146e-01],\n",
       "          ...,\n",
       "          [-3.4910e-01,  1.1586e+00, -8.8032e-02,  ...,  5.8754e-01,\n",
       "           -4.9121e-01,  2.9798e-01],\n",
       "          [-7.9571e-01,  6.5469e-01, -2.3097e-01,  ...,  1.8767e-01,\n",
       "            2.2454e-02,  2.1886e-01],\n",
       "          [ 1.3421e+00, -2.6196e-02, -9.3428e-01,  ..., -1.1959e-01,\n",
       "            9.3167e-01,  7.9816e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.1601e-02,  8.0273e-03,  4.8108e-03,  ...,  4.0573e-02,\n",
       "            4.6394e-02, -2.4876e-02],\n",
       "          [ 1.0827e-01, -2.6531e-01,  4.3838e-01,  ...,  2.6937e-01,\n",
       "           -3.1670e-01, -3.5829e-01],\n",
       "          [ 1.7490e-01,  6.6861e-01, -3.7073e-02,  ...,  1.7063e-01,\n",
       "           -1.0098e+00, -3.4741e-01],\n",
       "          ...,\n",
       "          [-1.1327e-01,  7.3457e-01, -1.3781e-01,  ..., -1.9057e-01,\n",
       "            1.8286e-01,  6.4631e-02],\n",
       "          [ 7.6553e-02,  2.0374e-01, -2.8055e-01,  ..., -1.0907e-01,\n",
       "            1.6577e+00,  5.2851e-01],\n",
       "          [ 2.2078e-01,  6.3766e-02, -5.3058e-01,  ...,  6.6232e-01,\n",
       "           -4.3177e-01, -9.8695e-01]],\n",
       "\n",
       "         [[-1.3773e-02,  5.5426e-03, -6.9476e-03,  ..., -2.9799e-02,\n",
       "            1.4209e-02,  2.0320e-02],\n",
       "          [ 6.8054e-02, -2.2634e-01, -1.4250e-01,  ..., -6.1924e-01,\n",
       "            1.7683e-01, -6.3840e-01],\n",
       "          [-1.7060e-01, -2.2828e-02, -4.4071e-01,  ..., -3.9321e-01,\n",
       "           -1.7372e-01,  3.2405e-01],\n",
       "          ...,\n",
       "          [-2.6056e-01,  4.5063e-01,  2.1455e-01,  ...,  4.2888e-01,\n",
       "            9.4979e-01,  1.0321e+00],\n",
       "          [ 1.0901e+00,  5.5897e-01,  2.5721e-01,  ..., -2.4082e-01,\n",
       "            6.3993e-01, -9.3008e-01],\n",
       "          [ 2.3740e-01, -4.8764e-01, -1.5073e-01,  ...,  1.8940e-01,\n",
       "           -4.0925e-02,  4.6536e-01]],\n",
       "\n",
       "         [[ 2.6770e-02, -1.6667e-02,  5.0951e-02,  ..., -4.4879e-02,\n",
       "           -8.8052e-03,  7.6909e-02],\n",
       "          [ 2.0199e-01, -3.2207e-01, -7.3491e-01,  ...,  2.4770e-01,\n",
       "            1.1235e-01,  6.0744e-01],\n",
       "          [-2.2061e-01,  3.3417e-01, -2.9517e-01,  ...,  6.0611e-02,\n",
       "            2.0470e-01, -5.6079e-01],\n",
       "          ...,\n",
       "          [-8.9025e-02,  1.4273e-01, -2.2335e-01,  ...,  4.8578e-01,\n",
       "           -8.1363e-02, -6.1109e-01],\n",
       "          [ 4.0854e-03, -3.6573e-02, -4.5565e-02,  ...,  2.6605e-01,\n",
       "            1.6726e-01,  3.7164e-01],\n",
       "          [ 5.7403e-01,  2.4011e-01, -7.5494e-02,  ..., -3.1132e-02,\n",
       "            1.8332e-01,  5.8962e-01]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 1.0686e+00, -2.1494e-01, -3.0324e-02,  ...,  5.0079e-01,\n",
       "            5.9858e-01, -2.4222e-01],\n",
       "          [-2.7594e+00, -8.9866e-01,  3.7951e-01,  ..., -6.2472e-01,\n",
       "           -4.8794e+00, -6.3645e-01],\n",
       "          [-3.7793e+00,  5.0722e-01, -7.9774e-01,  ..., -1.7550e-01,\n",
       "           -5.0220e+00, -4.8120e-01],\n",
       "          ...,\n",
       "          [-4.8558e+00, -1.6814e+00,  1.7952e+00,  ...,  4.4397e-01,\n",
       "           -1.6556e+00, -6.6224e-01],\n",
       "          [-3.8829e+00, -1.0434e-01,  3.0939e+00,  ..., -3.6253e-01,\n",
       "           -1.1442e+00,  1.3151e+00],\n",
       "          [-3.4864e+00, -1.7649e+00,  9.4112e-01,  ..., -1.1498e-01,\n",
       "           -1.2115e+00,  3.4221e-01]],\n",
       "\n",
       "         [[-1.4410e-01, -6.4411e-02,  6.8340e-02,  ..., -4.3281e-02,\n",
       "           -4.8844e-01, -1.5887e-01],\n",
       "          [-2.1357e+00,  1.5444e+00, -1.2029e+00,  ..., -3.2449e-02,\n",
       "            7.6411e-01,  1.2054e+00],\n",
       "          [-1.5949e+00,  4.4701e-01,  1.2090e-01,  ..., -5.9644e-01,\n",
       "            7.1239e-01,  4.4987e-01],\n",
       "          ...,\n",
       "          [-5.8707e-01, -7.3950e-01, -9.6476e-01,  ..., -1.1879e+00,\n",
       "            5.8804e-01, -4.9066e-01],\n",
       "          [-2.5020e+00,  1.0361e+00,  6.3637e-01,  ..., -1.5665e+00,\n",
       "            5.3848e-01, -1.1294e+00],\n",
       "          [-1.1512e+00,  6.4391e-01,  5.1807e-01,  ..., -1.0488e+00,\n",
       "           -1.0157e+00,  3.4309e-01]],\n",
       "\n",
       "         [[ 1.7880e-01,  1.0993e-01,  8.9950e-01,  ..., -3.1597e-01,\n",
       "            2.2744e-01, -3.0727e-01],\n",
       "          [-9.7994e-01, -1.3430e+00, -1.6630e+00,  ..., -9.3469e-01,\n",
       "           -5.2269e-01,  1.5710e+00],\n",
       "          [-1.8194e+00, -2.4407e+00, -1.0082e+00,  ..., -4.7933e-01,\n",
       "           -1.1263e+00,  1.2626e+00],\n",
       "          ...,\n",
       "          [ 2.0794e-01, -1.1735e+00,  1.9308e-03,  ...,  3.3339e+00,\n",
       "           -2.1898e+00,  1.5155e+00],\n",
       "          [ 1.0418e+00, -6.0071e-01,  4.0547e-01,  ...,  1.2423e+00,\n",
       "           -1.5363e+00,  1.9801e+00],\n",
       "          [ 9.1643e-01, -6.6356e-01, -8.3612e-01,  ...,  4.2854e-01,\n",
       "           -6.2007e-01,  1.5804e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9720e-01, -3.9990e-02, -2.6461e-01,  ...,  9.3571e-02,\n",
       "            2.4464e-02,  8.1061e-02],\n",
       "          [-1.6242e+00, -2.3000e-01,  3.7460e-01,  ...,  3.5858e-01,\n",
       "           -1.4993e+00,  3.6879e-01],\n",
       "          [-2.1187e+00, -6.3496e-01, -8.0300e-01,  ...,  1.0850e+00,\n",
       "           -8.3976e-01, -7.8631e-01],\n",
       "          ...,\n",
       "          [-3.4998e-01,  2.5139e-01,  4.0384e-01,  ...,  6.6542e-01,\n",
       "            3.7306e-01,  5.0276e-01],\n",
       "          [ 1.2154e+00,  3.7151e-01,  1.0229e+00,  ...,  5.9216e-02,\n",
       "            3.2231e-01, -1.8334e-02],\n",
       "          [-3.3006e-01,  1.1955e+00, -6.6711e-01,  ...,  2.8964e-01,\n",
       "            6.7352e-01, -1.0577e+00]],\n",
       "\n",
       "         [[-1.5052e-01, -1.4515e+00,  1.1103e-01,  ..., -9.9891e-02,\n",
       "           -6.0357e-03,  4.7894e-01],\n",
       "          [-3.2532e-04,  3.4954e+00, -9.3409e-01,  ..., -7.1982e-01,\n",
       "           -7.1569e-01,  5.5672e-01],\n",
       "          [ 5.4201e-01,  3.8898e+00, -1.2253e+00,  ...,  3.5593e-01,\n",
       "           -5.4377e-01, -1.1153e-01],\n",
       "          ...,\n",
       "          [-5.3420e-02,  6.3593e+00, -4.2412e-01,  ...,  2.8306e+00,\n",
       "            1.1478e-01,  1.5492e+00],\n",
       "          [ 1.4723e+00,  5.2543e+00,  8.2891e-01,  ...,  1.2599e+00,\n",
       "            1.1543e+00,  2.1056e+00],\n",
       "          [-2.8242e-01,  2.7215e+00, -6.8241e-01,  ...,  8.0616e-01,\n",
       "           -6.6468e-01, -4.7802e-01]],\n",
       "\n",
       "         [[ 1.4172e-01,  1.0974e-01,  1.4951e-02,  ...,  6.1647e-01,\n",
       "           -2.3998e-02,  7.6295e-02],\n",
       "          [ 7.3299e-02,  6.5383e-01, -1.3003e+00,  ...,  1.0928e+00,\n",
       "            2.4477e-01, -6.7514e-01],\n",
       "          [-5.7291e-01,  8.3899e-01, -1.2825e+00,  ...,  8.5838e-02,\n",
       "            1.6814e+00, -2.3486e-01],\n",
       "          ...,\n",
       "          [-1.1047e+00, -1.6446e+00,  8.3147e-01,  ..., -1.8222e-01,\n",
       "           -3.7433e-01,  6.6447e-02],\n",
       "          [-9.4818e-01, -2.6830e-01,  6.4203e-01,  ..., -9.2383e-01,\n",
       "            1.8384e-02,  5.3073e-01],\n",
       "          [-1.1899e-01,  1.1810e+00,  9.5500e-01,  ..., -4.8488e-01,\n",
       "           -3.8032e-02,  6.4974e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-3.6648e-02,  3.4762e-02, -1.1658e-02,  ...,  6.4356e-03,\n",
       "           -1.9044e-02,  3.1455e-02],\n",
       "          [-8.3922e-01,  8.0180e-02,  2.9083e-02,  ..., -1.1066e-02,\n",
       "           -1.4988e-01,  5.8259e-03],\n",
       "          [-9.4625e-02, -4.5247e-01,  7.9862e-01,  ...,  7.2338e-01,\n",
       "           -2.1049e-01,  3.7635e-01],\n",
       "          ...,\n",
       "          [ 1.0917e-01,  3.3420e-01,  1.2892e+00,  ..., -4.9706e-02,\n",
       "           -1.3616e+00,  1.4428e+00],\n",
       "          [-5.0430e-01, -7.4538e-01,  3.9545e-01,  ...,  5.6215e-01,\n",
       "           -6.0251e-01,  5.0726e-01],\n",
       "          [ 5.3280e-02,  2.4202e-01, -9.9013e-02,  ..., -1.3522e+00,\n",
       "            5.4876e-02,  1.4562e-01]],\n",
       "\n",
       "         [[ 3.0907e-03, -4.1116e-02,  7.8380e-04,  ...,  2.0266e-02,\n",
       "           -1.2090e-02,  2.7770e-02],\n",
       "          [ 2.8982e-02, -3.1680e-01, -9.1219e-02,  ...,  1.9834e-01,\n",
       "            9.4746e-01,  6.8335e-01],\n",
       "          [ 3.1958e-02,  3.8626e-01, -5.3713e-01,  ...,  9.1834e-02,\n",
       "           -5.2963e-01,  4.0854e-01],\n",
       "          ...,\n",
       "          [ 8.3693e-02, -2.1509e-01, -9.6692e-01,  ...,  1.0053e-03,\n",
       "            1.6313e-01, -1.2414e-01],\n",
       "          [ 7.6506e-01, -6.4713e-01, -7.8031e-01,  ...,  3.1223e-01,\n",
       "            3.1572e-02, -7.2380e-01],\n",
       "          [ 1.0263e+00, -9.7971e-04,  1.3264e-01,  ...,  5.2272e-01,\n",
       "            4.7679e-01,  2.2245e-01]],\n",
       "\n",
       "         [[ 3.0886e-02, -1.5280e-02,  5.3276e-02,  ...,  4.0481e-02,\n",
       "           -1.2018e-02, -2.6005e-02],\n",
       "          [ 1.0224e+00,  1.1545e+00, -1.1163e+00,  ...,  1.1484e-01,\n",
       "            1.6381e-01, -2.4746e-01],\n",
       "          [ 1.3180e+00,  1.9920e+00,  6.8734e-01,  ...,  1.2127e+00,\n",
       "           -7.3545e-01, -6.2403e-01],\n",
       "          ...,\n",
       "          [ 8.3001e-02,  9.1801e-01, -1.1144e+00,  ..., -6.0922e-02,\n",
       "            1.2663e+00,  7.3568e-01],\n",
       "          [-2.5656e-01,  1.3591e+00, -6.4208e-01,  ...,  4.8372e-01,\n",
       "           -5.6687e-01, -2.5022e+00],\n",
       "          [-7.1135e-01, -1.0281e-01,  2.9979e-01,  ..., -1.4594e+00,\n",
       "            1.4156e+00, -4.9704e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0287e-02, -3.8271e-02, -2.3777e-02,  ..., -1.9104e-02,\n",
       "           -3.3094e-02, -5.2524e-02],\n",
       "          [ 3.8692e-01,  3.0416e-02, -1.1654e-01,  ..., -6.8468e-01,\n",
       "            1.2581e-01,  1.1904e-01],\n",
       "          [-5.1505e-01, -5.3135e-01,  4.4139e-01,  ..., -3.8607e-01,\n",
       "           -1.9620e-01, -5.0339e-01],\n",
       "          ...,\n",
       "          [-1.7234e-01,  8.3903e-01, -5.1168e-01,  ..., -5.9702e-02,\n",
       "           -1.0204e+00, -4.4108e-01],\n",
       "          [ 8.9945e-01, -2.6882e-01, -1.0790e+00,  ..., -2.1897e-01,\n",
       "           -5.1370e-01, -2.0851e-02],\n",
       "          [-1.2993e-01,  1.4431e+00, -4.8181e-01,  ...,  8.2522e-02,\n",
       "            1.6306e+00,  7.8322e-01]],\n",
       "\n",
       "         [[-2.8157e-01, -1.3383e-03, -1.6394e-02,  ..., -6.9669e-03,\n",
       "            3.8162e-03, -2.5312e-02],\n",
       "          [-1.6196e+00, -7.3031e-02, -2.5538e-01,  ...,  3.1915e-01,\n",
       "           -2.2301e-01,  9.7324e-01],\n",
       "          [-1.4536e+00, -4.2739e-01,  2.2416e-01,  ...,  1.0247e+00,\n",
       "            1.3257e+00, -4.0806e-01],\n",
       "          ...,\n",
       "          [-1.2963e+00,  1.2249e+00, -1.4197e-01,  ...,  1.5315e-01,\n",
       "           -1.1360e+00, -1.1534e+00],\n",
       "          [-1.5653e+00,  2.5551e-01, -8.8415e-01,  ...,  4.6188e-01,\n",
       "            2.9548e-01, -7.2829e-01],\n",
       "          [-1.7427e+00,  5.5670e-02, -6.2371e-01,  ..., -9.1507e-01,\n",
       "            9.7325e-01,  1.3177e-01]],\n",
       "\n",
       "         [[ 2.8468e-02,  1.3434e-02,  2.3018e-02,  ...,  1.2052e-02,\n",
       "            7.4262e-03, -1.4572e-02],\n",
       "          [-7.8025e-01,  1.4776e+00, -2.4131e-01,  ...,  4.2456e-01,\n",
       "           -1.2376e+00,  1.3058e+00],\n",
       "          [-3.8911e-01,  8.4748e-02, -2.9863e-01,  ..., -4.8552e-01,\n",
       "           -1.0309e+00, -5.1688e-01],\n",
       "          ...,\n",
       "          [-2.3053e-01,  2.5056e-01, -1.3724e-02,  ..., -2.2485e-01,\n",
       "           -7.3035e-01, -8.6754e-01],\n",
       "          [ 6.8068e-02, -1.5494e-02, -8.9881e-01,  ..., -5.9201e-01,\n",
       "           -2.3078e+00, -1.3570e-01],\n",
       "          [-4.3325e-01,  1.7833e-01,  2.3475e-01,  ..., -6.3680e-01,\n",
       "            5.1468e-02,  1.4821e+00]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 3.2174e-02, -2.4102e-01, -5.7201e-01,  ...,  2.3488e-01,\n",
       "            4.4958e-01,  3.7742e-01],\n",
       "          [ 1.5948e-01, -1.1179e-01, -1.8252e+00,  ...,  1.9472e-01,\n",
       "           -6.6066e-01,  4.0678e-01],\n",
       "          [-1.1177e+00, -1.4909e-02, -6.5297e-01,  ...,  1.4604e+00,\n",
       "            4.8727e-01, -4.8058e-01],\n",
       "          ...,\n",
       "          [ 3.3890e-01, -4.0425e-01,  2.1676e-01,  ...,  1.3730e+00,\n",
       "            2.2391e+00, -6.2685e-01],\n",
       "          [ 7.1381e-01, -9.5849e-01, -5.4617e-01,  ...,  1.9231e+00,\n",
       "            1.2709e+00,  5.1735e-01],\n",
       "          [ 1.3945e+00,  5.0760e-01, -2.9131e-01,  ...,  2.5949e+00,\n",
       "           -3.3362e-01, -2.1152e-01]],\n",
       "\n",
       "         [[-1.9406e-01, -2.2276e-04,  6.4814e-02,  ..., -4.1252e-03,\n",
       "           -9.9358e-01, -1.3207e-01],\n",
       "          [-8.1626e-02,  3.3378e-01, -4.8362e-01,  ..., -3.4461e-01,\n",
       "           -1.4796e-01,  7.6209e-01],\n",
       "          [-8.7202e-03, -9.2320e-01, -6.1598e-01,  ...,  8.4392e-02,\n",
       "            2.2459e-02,  1.2244e+00],\n",
       "          ...,\n",
       "          [ 5.5060e-01,  2.2155e-01, -1.2212e+00,  ..., -4.3012e-01,\n",
       "           -1.0220e+00,  2.1247e+00],\n",
       "          [ 1.5687e+00,  6.5114e-01, -5.1459e-01,  ..., -1.5352e+00,\n",
       "           -1.5604e+00,  1.8831e+00],\n",
       "          [-1.1494e+00,  7.8138e-01, -7.8124e-01,  ..., -1.0249e+00,\n",
       "            1.9182e+00, -1.3496e-01]],\n",
       "\n",
       "         [[-1.0132e+00,  4.2454e-02,  4.7795e-01,  ..., -6.6415e-01,\n",
       "            4.0562e-01, -6.6226e-02],\n",
       "          [ 4.7675e-02,  2.2702e-01, -7.1813e-01,  ...,  8.0179e-01,\n",
       "           -1.7486e+00, -6.8858e-02],\n",
       "          [ 1.3998e+00, -1.4107e-01, -1.0304e+00,  ...,  1.6023e+00,\n",
       "           -4.9856e-01, -8.9218e-01],\n",
       "          ...,\n",
       "          [ 1.3326e+00,  1.5327e+00,  4.6387e-01,  ...,  8.8988e-01,\n",
       "            8.7261e-01, -1.4026e+00],\n",
       "          [ 1.5732e+00,  2.1723e+00,  5.1404e-01,  ...,  7.6735e-01,\n",
       "            3.7101e-01,  3.1034e-01],\n",
       "          [ 1.0896e+00,  2.5813e+00,  5.0846e-01,  ...,  1.0391e-01,\n",
       "           -1.8674e+00,  7.8963e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.2705e-01, -8.7197e-01, -3.8396e-01,  ..., -9.0624e-01,\n",
       "           -4.6313e-01,  5.8384e-01],\n",
       "          [ 1.0159e+00, -1.1217e+00, -1.8608e+00,  ...,  3.5666e-01,\n",
       "           -4.3525e-01,  1.0817e-01],\n",
       "          [ 5.8807e-01, -9.0983e-01, -2.1078e+00,  ...,  2.1713e-01,\n",
       "            5.3759e-02,  2.8122e-01],\n",
       "          ...,\n",
       "          [ 6.0829e-01,  6.4624e-01,  1.3068e-01,  ..., -6.7594e-01,\n",
       "           -1.7793e+00, -2.8765e-01],\n",
       "          [-2.1823e-01,  2.2790e+00, -1.1736e+00,  ..., -1.6016e+00,\n",
       "           -1.8271e+00, -1.3204e+00],\n",
       "          [ 1.1147e+00,  7.1523e-01, -1.8321e+00,  ..., -3.9065e-01,\n",
       "           -8.6290e-01, -2.8922e-01]],\n",
       "\n",
       "         [[-7.3037e-01,  2.4232e+00,  3.5321e-01,  ...,  2.1305e-01,\n",
       "            1.9155e+00, -4.5689e-01],\n",
       "          [ 1.0649e+00, -1.1268e+00,  1.4550e-01,  ...,  5.8560e-01,\n",
       "           -1.8865e+00,  2.1172e+00],\n",
       "          [ 5.6800e-01, -1.5438e+00,  6.0945e-01,  ...,  3.5797e-02,\n",
       "           -1.6188e+00,  2.1796e+00],\n",
       "          ...,\n",
       "          [ 6.6971e-01, -6.4302e+00,  2.0391e+00,  ..., -1.1302e+00,\n",
       "           -3.8843e+00, -1.5199e+00],\n",
       "          [-6.9288e-01, -5.1785e+00,  1.3732e+00,  ...,  5.5884e-01,\n",
       "           -3.0336e+00, -1.3004e+00],\n",
       "          [ 5.4176e-02, -5.2774e+00,  5.1485e-01,  ..., -5.2554e-01,\n",
       "           -4.1325e+00,  1.2595e+00]],\n",
       "\n",
       "         [[-1.7974e+00, -2.7307e-01, -1.0514e+00,  ..., -4.3419e-01,\n",
       "            1.3528e-01,  2.3259e-01],\n",
       "          [ 8.4151e-01,  7.1023e-01,  7.6247e-01,  ...,  2.3784e-01,\n",
       "            1.8046e-01,  1.3402e-01],\n",
       "          [ 1.3370e+00,  2.6978e-01,  4.4579e-01,  ...,  3.8593e-01,\n",
       "            8.5267e-02,  5.8597e-01],\n",
       "          ...,\n",
       "          [ 3.0871e+00,  1.3650e-01,  1.3797e-01,  ..., -6.0718e-01,\n",
       "           -4.9736e-01,  5.0917e-01],\n",
       "          [ 2.6028e+00, -6.2702e-01,  1.2477e+00,  ..., -3.4361e-01,\n",
       "            2.8480e-01,  1.8505e-02],\n",
       "          [ 2.8306e+00,  1.1577e+00,  3.0438e+00,  ..., -2.4058e-01,\n",
       "           -4.7177e-01, -2.3095e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-2.2390e-02, -1.8661e-02, -2.8744e-02,  ...,  4.9898e-02,\n",
       "           -1.9839e-02,  1.8703e-02],\n",
       "          [-4.8148e-01,  8.2623e-02,  1.6555e-01,  ..., -1.4347e-02,\n",
       "            2.3291e-01,  1.0549e-01],\n",
       "          [-7.7064e-01, -3.2667e-01,  1.7524e-01,  ...,  5.5388e-01,\n",
       "            1.8446e+00,  9.4648e-01],\n",
       "          ...,\n",
       "          [ 7.0960e-01,  7.6641e-01, -1.3429e+00,  ...,  1.3262e+00,\n",
       "           -2.8603e-02, -1.0413e+00],\n",
       "          [-1.5734e+00, -9.4457e-02, -1.7241e+00,  ...,  1.6421e+00,\n",
       "           -4.5045e-01, -9.2847e-02],\n",
       "          [-3.9832e-01,  4.7325e-01, -8.4159e-01,  ...,  1.1999e+00,\n",
       "           -3.4875e-01, -7.5709e-01]],\n",
       "\n",
       "         [[-1.7354e-02, -5.4510e-03, -9.5227e-03,  ..., -9.4763e-03,\n",
       "            2.3977e-02,  1.3102e-02],\n",
       "          [-3.6341e-01,  3.5187e-01,  6.9499e-01,  ..., -5.2005e-01,\n",
       "           -2.9833e-01,  1.6953e-01],\n",
       "          [ 2.3776e-01,  9.9075e-03, -2.3481e+00,  ..., -5.5052e-02,\n",
       "           -4.2117e-01, -6.7794e-01],\n",
       "          ...,\n",
       "          [-3.7148e-01,  7.1744e-01,  1.2900e-01,  ...,  4.6066e-01,\n",
       "           -1.3818e+00, -5.3881e-01],\n",
       "          [-9.3222e-02, -1.2875e-02, -6.3135e-01,  ..., -1.1394e-01,\n",
       "           -5.2847e-01,  1.3754e-01],\n",
       "          [-3.5692e-01,  9.3021e-01,  3.3430e-01,  ...,  1.6325e-01,\n",
       "            1.4367e+00, -9.2226e-01]],\n",
       "\n",
       "         [[-1.4864e-02,  2.4805e-02, -9.2249e-03,  ...,  1.4381e-02,\n",
       "            3.8777e-03, -1.9761e-02],\n",
       "          [-4.4678e-01, -7.0613e-02, -1.8827e-01,  ...,  2.6236e-01,\n",
       "           -8.8777e-02, -6.7496e-01],\n",
       "          [ 3.5457e-01, -8.7490e-01,  8.3774e-01,  ...,  5.9060e-01,\n",
       "           -9.9168e-02, -5.1299e-01],\n",
       "          ...,\n",
       "          [-2.1352e+00,  4.2575e-02,  1.0898e+00,  ..., -5.2945e-02,\n",
       "           -3.6558e-01, -1.1299e+00],\n",
       "          [-2.2658e+00,  8.8373e-01, -8.3113e-01,  ...,  4.9491e-01,\n",
       "           -1.0702e+00, -7.9498e-01],\n",
       "          [-6.6703e-01,  3.6016e-01, -6.8782e-01,  ...,  1.0956e-01,\n",
       "           -3.1863e-01, -8.9098e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.8822e-03,  1.8815e-02,  2.0581e-02,  ..., -4.9082e-02,\n",
       "            2.1781e-02, -1.5297e-02],\n",
       "          [-2.4621e-01, -2.0182e-01,  1.7503e-01,  ...,  2.1855e-01,\n",
       "            1.0363e+00,  1.0658e+00],\n",
       "          [ 2.6673e-01, -1.9759e-01, -1.4425e-01,  ...,  2.7383e-02,\n",
       "            5.3646e-01, -4.3505e-01],\n",
       "          ...,\n",
       "          [-2.7902e-01,  3.7437e-01,  7.5132e-01,  ...,  6.6551e-01,\n",
       "            7.1018e-01,  5.4577e-01],\n",
       "          [-9.4719e-01, -2.8442e-01,  7.7575e-01,  ..., -2.1382e-01,\n",
       "           -9.8157e-01, -5.8458e-01],\n",
       "          [ 1.4143e+00, -2.9503e-01, -1.4429e-01,  ..., -8.8044e-01,\n",
       "            4.8122e-01, -2.0876e+00]],\n",
       "\n",
       "         [[ 2.4624e-02, -2.2552e-02, -4.7497e-02,  ..., -3.6804e-03,\n",
       "            3.3300e-04, -5.8023e-02],\n",
       "          [ 2.8326e-01,  5.2202e-02, -8.3360e-02,  ..., -9.7684e-02,\n",
       "            5.3497e-01, -7.0576e-04],\n",
       "          [ 1.5535e-01,  7.4792e-01, -4.2137e-02,  ...,  1.3929e-01,\n",
       "            4.9013e-01,  6.4888e-01],\n",
       "          ...,\n",
       "          [ 1.1777e+00,  2.3267e-01, -5.1839e-01,  ...,  1.1586e-01,\n",
       "           -3.1136e-01, -4.3031e-01],\n",
       "          [ 1.2005e+00,  1.8727e-01, -7.0267e-02,  ...,  9.1724e-02,\n",
       "           -4.6911e-01, -3.5144e-01],\n",
       "          [-8.5402e-01, -1.7033e-01, -3.7027e-01,  ...,  4.3215e-01,\n",
       "            7.4432e-01,  5.8458e-01]],\n",
       "\n",
       "         [[ 4.4184e-02,  3.0890e-03,  1.9318e-02,  ..., -4.0138e-02,\n",
       "            1.4674e-02, -1.2232e-02],\n",
       "          [-3.5666e-01, -4.1124e-01,  1.0745e+00,  ...,  2.8398e-01,\n",
       "           -2.1475e+00, -4.0562e-01],\n",
       "          [-3.2722e-01, -2.8023e-01, -2.1007e-01,  ...,  1.3176e+00,\n",
       "           -2.1662e-02, -1.0397e+00],\n",
       "          ...,\n",
       "          [ 1.8429e-01, -1.7950e-01,  2.1911e-01,  ..., -4.7671e-01,\n",
       "            3.9148e-01, -9.0124e-01],\n",
       "          [-1.4564e-01, -2.1575e+00,  2.7560e-01,  ..., -3.7213e-01,\n",
       "            1.1470e+00,  5.6872e-01],\n",
       "          [-5.8532e-01, -1.8459e+00, -4.9705e-01,  ..., -1.1088e-01,\n",
       "           -5.1621e-01,  3.8420e-02]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[-1.6659, -0.4115, -0.4219,  ...,  0.2726,  0.3571, -0.4753],\n",
       "          [-0.2541,  0.1571, -0.8994,  ...,  0.8401, -1.3719,  0.2143],\n",
       "          [-0.3802,  0.6494,  0.2953,  ...,  0.9340, -1.2266, -0.2034],\n",
       "          ...,\n",
       "          [ 0.3822, -0.2016,  0.3325,  ..., -0.1818,  0.4124,  0.8706],\n",
       "          [ 0.9743,  0.2913, -0.2909,  ..., -0.1777, -1.4397, -0.0788],\n",
       "          [ 2.3719,  0.8086, -0.2655,  ..., -1.0109, -2.8108, -0.8903]],\n",
       "\n",
       "         [[ 0.0356, -0.1796,  1.9541,  ...,  0.2676,  0.0812, -0.2355],\n",
       "          [ 0.8267, -0.8010, -1.2228,  ...,  1.2827, -0.1398, -0.7756],\n",
       "          [ 0.0766, -0.7449, -1.3887,  ...,  0.3241,  0.0408, -0.6088],\n",
       "          ...,\n",
       "          [-0.8274, -0.6624, -1.6310,  ..., -0.0503,  0.3107, -0.8156],\n",
       "          [-0.7977, -0.6467,  0.9945,  ..., -0.6117,  0.4955, -0.6946],\n",
       "          [-0.1143,  0.2376, -0.7460,  ...,  0.3351,  0.2388,  0.4972]],\n",
       "\n",
       "         [[ 0.0217,  0.8810,  0.5240,  ..., -0.5847,  0.3164, -0.0778],\n",
       "          [-0.4159,  0.6807,  0.0162,  ...,  1.2126,  0.2980, -0.3833],\n",
       "          [-0.0753,  0.3869,  0.1309,  ...,  1.2587,  0.0462, -0.1458],\n",
       "          ...,\n",
       "          [ 0.2742,  0.0652, -0.4962,  ...,  0.7194, -0.1338,  0.1589],\n",
       "          [-0.5549, -1.2507, -0.3541,  ...,  0.6840, -1.1074, -0.3953],\n",
       "          [-0.5150, -0.1565, -0.4365,  ...,  0.8146,  0.8989,  0.2364]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.6763,  0.9552, -0.9797,  ..., -0.7165,  0.6628,  0.8646],\n",
       "          [ 0.4389, -0.4757, -0.5722,  ..., -0.7067, -0.0583,  0.1297],\n",
       "          [-0.0770, -0.0386, -0.4853,  ..., -0.4239,  0.0690, -0.1002],\n",
       "          ...,\n",
       "          [-1.0683, -0.4408, -0.4693,  ...,  1.1594, -0.8923, -0.9372],\n",
       "          [-0.3071, -0.7028, -0.8941,  ...,  1.1807,  0.4342, -0.6931],\n",
       "          [ 0.1306, -1.3423, -0.7848,  ...,  0.3803, -0.5571, -0.3936]],\n",
       "\n",
       "         [[-0.3571,  0.3051,  0.7888,  ...,  0.5539, -0.1589, -0.3462],\n",
       "          [-0.5631,  0.9083, -1.3401,  ...,  0.4380, -0.1544, -1.1002],\n",
       "          [ 0.3593,  0.7401,  0.1584,  ...,  1.0055, -1.1135, -0.8594],\n",
       "          ...,\n",
       "          [-0.8434, -0.5447,  0.7077,  ...,  0.7304, -2.3337, -0.6479],\n",
       "          [-1.3077, -0.4283,  1.0094,  ..., -0.0349,  0.2929,  0.2045],\n",
       "          [-0.9768, -0.3686, -1.0956,  ..., -0.4731, -0.5029, -1.3090]],\n",
       "\n",
       "         [[-0.7106, -0.1670,  0.3566,  ...,  0.0393,  0.0498,  0.0743],\n",
       "          [ 0.2735,  0.2561,  1.4062,  ...,  0.8140, -0.1091,  0.4681],\n",
       "          [ 0.8903,  0.2642,  1.0442,  ...,  0.4518,  0.0884,  1.4406],\n",
       "          ...,\n",
       "          [-0.6696, -1.7097,  0.8140,  ...,  0.1184,  0.4578,  1.0320],\n",
       "          [ 0.4760,  0.1325,  0.7602,  ...,  0.1689, -0.1301,  0.6722],\n",
       "          [ 0.2771, -0.4947,  1.4571,  ...,  1.4158,  0.9218,  0.6843]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-6.0560e-02, -5.2135e-03,  1.7899e-02,  ...,  5.1741e-02,\n",
       "            4.5947e-02, -4.3915e-02],\n",
       "          [-9.3102e-01,  1.6411e-02,  9.1747e-01,  ...,  1.3427e+00,\n",
       "           -1.4354e+00,  1.9299e+00],\n",
       "          [-6.8928e-01, -4.0056e-02,  1.0434e+00,  ...,  2.3262e+00,\n",
       "           -2.4408e+00,  1.9615e+00],\n",
       "          ...,\n",
       "          [-1.7538e-01, -4.1026e-01,  1.3586e+00,  ...,  5.5459e-01,\n",
       "           -2.6309e+00,  7.5631e-01],\n",
       "          [ 5.0033e-01, -8.8112e-02,  1.8298e+00,  ..., -4.1289e-01,\n",
       "           -1.3615e+00, -1.7168e-01],\n",
       "          [-3.0455e+00,  9.4746e-01,  1.1039e+00,  ...,  1.1451e+00,\n",
       "           -2.1697e+00, -2.8323e-02]],\n",
       "\n",
       "         [[-7.2585e-02, -2.1744e-02, -2.7473e-02,  ..., -9.1009e-02,\n",
       "           -2.0906e-02,  6.8024e-04],\n",
       "          [ 5.7351e-02, -9.1970e-02, -2.2772e-01,  ..., -4.3507e-01,\n",
       "           -6.3549e-01, -1.8139e-01],\n",
       "          [-6.8487e-01, -5.9930e-01, -4.1832e-01,  ..., -7.5917e-02,\n",
       "           -5.6973e-01,  1.0003e-01],\n",
       "          ...,\n",
       "          [ 2.2758e-01,  4.7393e-01,  3.3718e-01,  ..., -3.4836e-01,\n",
       "           -1.0617e+00, -6.3159e-01],\n",
       "          [-2.3372e-01,  3.8172e-01, -1.6643e+00,  ...,  7.8333e-01,\n",
       "            8.0302e-01, -1.3460e+00],\n",
       "          [ 8.9412e-01, -9.3601e-01, -2.2438e-01,  ..., -3.6994e-02,\n",
       "            2.7469e-01,  8.9574e-01]],\n",
       "\n",
       "         [[-2.0771e-02,  2.4828e-02,  5.4903e-02,  ...,  2.3370e-02,\n",
       "            1.4368e-02,  5.2393e-02],\n",
       "          [ 1.0770e+00, -2.6552e-01, -4.6519e-01,  ...,  2.6388e-01,\n",
       "            1.0045e-01,  4.2674e-02],\n",
       "          [-2.6654e-01,  4.1844e-01, -8.5250e-01,  ..., -7.3077e-01,\n",
       "           -5.8578e-02,  8.6453e-02],\n",
       "          ...,\n",
       "          [ 4.2865e-01, -2.9616e-01, -1.2485e+00,  ...,  3.8668e-01,\n",
       "            4.8478e-02,  3.4914e-01],\n",
       "          [ 1.8121e+00, -6.9445e-01,  6.5963e-01,  ..., -7.9136e-01,\n",
       "           -1.2381e+00,  2.4505e-01],\n",
       "          [ 1.9246e+00, -1.3675e+00,  3.8043e-01,  ..., -1.3074e+00,\n",
       "            2.0354e+00,  3.0445e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.0925e-02,  2.0566e-02, -5.3920e-02,  ...,  3.0711e-03,\n",
       "            2.2759e-02, -7.1719e-02],\n",
       "          [-9.0934e-02, -2.2874e-01, -3.0689e-01,  ..., -2.5865e-01,\n",
       "            6.5570e-01, -2.2725e-01],\n",
       "          [-2.0612e-01,  3.5672e-01,  4.6812e-01,  ..., -2.1401e-01,\n",
       "            9.9206e-01,  2.0954e-01],\n",
       "          ...,\n",
       "          [-7.4325e-01, -8.9846e-01, -1.1544e+00,  ...,  1.1869e+00,\n",
       "           -8.3032e-01,  2.5958e-02],\n",
       "          [-7.5098e-01,  1.9287e-01, -1.0363e+00,  ...,  1.3796e+00,\n",
       "            2.7070e+00, -1.5305e+00],\n",
       "          [-1.4324e-01, -5.3008e-01, -4.0202e-01,  ...,  4.7417e-01,\n",
       "            9.6558e-01,  4.4559e-01]],\n",
       "\n",
       "         [[ 1.5795e-02, -3.2110e-03,  2.6768e-02,  ..., -1.4629e-02,\n",
       "            6.0780e-02, -1.7437e-02],\n",
       "          [-1.3324e-01,  7.0727e-02,  2.6995e-01,  ...,  1.5596e-01,\n",
       "            3.5427e-01, -2.3768e-02],\n",
       "          [ 4.6147e-03,  3.9939e-01, -8.3894e-01,  ...,  1.2716e+00,\n",
       "            1.5137e+00, -5.0891e-01],\n",
       "          ...,\n",
       "          [ 3.8700e-01,  1.2631e+00,  9.5753e-01,  ...,  2.3752e+00,\n",
       "            8.6163e-01, -7.2075e-01],\n",
       "          [-1.5776e-01,  9.9655e-01,  4.4652e-01,  ...,  1.3794e+00,\n",
       "            8.9260e-01, -2.4833e-02],\n",
       "          [-1.7370e+00, -1.0385e-01,  8.1181e-01,  ...,  4.7064e-02,\n",
       "           -1.8963e-01, -1.8408e-01]],\n",
       "\n",
       "         [[-4.9851e-02,  1.5951e-02,  5.7044e-02,  ..., -6.6552e-02,\n",
       "           -2.7041e-02, -4.5257e-02],\n",
       "          [-1.0368e-01,  6.9066e-01,  4.7647e-01,  ..., -3.1482e-02,\n",
       "           -3.1079e-01,  1.9866e-01],\n",
       "          [-2.6873e-01,  1.1955e-01,  1.1576e-01,  ..., -2.8948e-01,\n",
       "           -1.1867e+00,  3.1058e-02],\n",
       "          ...,\n",
       "          [ 1.4075e-01, -3.6259e-01, -1.3983e-01,  ..., -8.3127e-02,\n",
       "            6.0878e-01,  1.3044e-01],\n",
       "          [-4.8969e-01, -8.2570e-01,  8.3739e-01,  ...,  3.2761e-01,\n",
       "            6.4441e-02, -2.1668e-01],\n",
       "          [-9.5773e-01,  7.8387e-01,  2.0237e-01,  ..., -1.0202e-01,\n",
       "           -7.7003e-01, -5.3013e-01]]]], grad_fn=<TransposeBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick check that things are working\n",
    "\n",
    "inputs = tokenizer(ds['train'][0]['text'], return_tensors=\"pt\")\n",
    "inputs['input_ids'].shape\n",
    "#print(tokenizer.decode(inputs['input_ids']))\n",
    "outputs = lora_model(**inputs)  # Forward pass with the tokenized inputs\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396449e",
   "metadata": {},
   "source": [
    "Define a function to group the *tokenized* text into smaller (block size 128) chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75727e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the tokenized texts into chunks and also copy the unput_ids to labels\n",
    "# labels don't really matter here for this text generation model\n",
    "block_size = 128\n",
    "def chunk_texts(examples):\n",
    "    concatenated = {}\n",
    "    for k, v in examples.items():\n",
    "        concatenated[k] = sum(v, [])\n",
    "\n",
    "    total_length = len(concatenated[list(examples.keys())[0]])\n",
    "    # just drop the small remainder\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks\n",
    "    result = {}\n",
    "    for k, v in concatenated.items():\n",
    "        result[k] = [v[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52eba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the simple tokenization first and drop the un-used features.\n",
    "\n",
    "tokenized_datasets = {}\n",
    "for split in ds.keys():\n",
    "    tokenized_datasets[split] = ds[split].map(\n",
    "        lambda x: tokenizer(x['text']),\n",
    "        batched=True,\n",
    "        remove_columns=[\"conversation_id\", \"speaker\", \"date_time\", \"text\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "456d4ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4500/4500 [00:00<00:00, 15895.78 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 22331.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# complete the preprocessing with grouping\n",
    "preprocessed_ds = {split : tokenized_datasets[split].map(\n",
    "    chunk_texts,\n",
    "    batched=True,\n",
    ") for split in tokenized_datasets.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8c54e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['input_ids', 'attention_mask', 'labels'],\n",
       "     num_rows: 1006\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['input_ids', 'attention_mask', 'labels'],\n",
       "     num_rows: 107\n",
       " })}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91eb4c",
   "metadata": {},
   "source": [
    "#### Set the training Arguments and the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db1246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/lora-bank-gpt2\",\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e47944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# let the data_collator handle the batching jobs\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors=\"pt\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=preprocessed_ds['train'],\n",
    "    eval_dataset=preprocessed_ds['test'],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a865c8",
   "metadata": {},
   "source": [
    "#### Now train the model. Without GPU, this will take a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f32ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 02:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.786400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=126, training_loss=3.7301211130051386, metrics={'train_runtime': 135.8309, 'train_samples_per_second': 7.406, 'train_steps_per_second': 0.928, 'total_flos': 32915029229568.0, 'train_loss': 3.7301211130051386, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangbing/pysrc/Udacity/genAIIntro/.venv/lib64/python3.13/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 5.3056, 'eval_samples_per_second': 20.167, 'eval_steps_per_second': 2.639, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned model\n",
    "from transformers import pipeline\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ‚ö†Ô∏è IMPORTANT ‚ö†Ô∏è\n",
    "\n",
    "Due to workspace storage constraints, we should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "save_path = \"/tmp/lora-bank-gpt2\"\n",
    "lora_model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: I need to open a checking account\n",
      "[{'generated_text': 'I need to open a checking account for the current account. We will check that account too. But the account has failed to close.\\n\\n\\n\\nWhat is the state of our service?\\nThis depends on the service. In your case, we were looking for a new account, but we did not find the new account. We would need to send a check message to the service.\\nWhat is the state of our service?\\nWe are looking for a new account, but the service has failed to close.\\nWhat does the state of our service?\\nThe state of our service depends on your service. In your case, we were looking for a new account, but we did not find the new account. We would need to send a check message to the service.\\nWhat is the state of our service?\\nThe state of our service depends on your service. In your case, we were looking for a new account, but we did not find the new account. We would need to send a check message to the service.\\nWhat is the state of our service?\\nWe are looking for a new account, but the service has failed to close.\\nWhat is the state of our service?\\nThe state of our service depends on your service. In your case, we were'}]\n",
      "Prompt: I want to apply for a credit card\n",
      "[{'generated_text': \"I want to apply for a credit card to my college degree, so I'll make sure that I have enough credit card to cover the rest of my expenses for my college.\\n\\n\\n\\nI'll also be on the phone with a friend about my decision to take an interest-free, life changing, and life changing college trip.\\nWhat you need to know:\\nWhat you need to know:\\nHow to check your credit card to get a credit card.\\nWhat you need to know:\\nHow to check your credit card to get a credit card.\\nWhat you need to know:\\nWhat you need to know:\\nHow to check your credit card to get a credit card.\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you need to know:\\nWhat you\"}]\n",
      "Prompt: I want to transfer money to my savings account\n",
      "[{'generated_text': 'I want to transfer money to my savings account. I can\\'t afford it.\"\\n\\n\\n\\n\\n\"I\\'m not going to do this because my savings account is not going to be going to be going to be going to my savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I is not going to be going to the savings account. I don\\'t want to do this because I am not going to be going to the savings account. I don\\'t want to do this because I am not going to be going'}]\n",
      "Prompt: I need to setup automatic payments for my utilities\n",
      "[{'generated_text': 'I need to setup automatic payments for my utilities.\\n\\n\\n\\nTo get the basic idea for how to perform automatic payments, first, we have to go through the following steps:\\n1. Login to your account and login to your account\\n2. Register your account and login to the account\\n3. Go to the payment.com/payments.com/payments.com/payments.php\\nPayments are made using the following methods:\\n1. Login to your account\\n2. Login to your account\\n3. Login to your account\\n4. Login to your account\\n5. Login to your account\\n6. Login to your account\\n7. Login to your account\\n8. Login to your account\\n9. Login to your account\\n10. Login to your account\\n11. Login to your account\\n12. Login to your account\\n13. Login to your account\\n14. Login to your account\\n15. Login to your account\\n16. Login to your account\\n17. Login to your account\\n18. Login to your account\\n19. Login to your account\\n20. Login to your account\\n21. Login to your account\\n22. Login to your account\\n23. Login to your account\\n24. Login to your account\\n25.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the fine-tuned model for inference\n",
    "finetuned_model = pipeline(\"text-generation\", model=save_path, tokenizer=tokenizer)\n",
    "\n",
    "# Generate responses for the same prompts\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(finetuned_model(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a8147",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The fine-tuned model does a better job in the area of finance related topics as the additional training\n",
    "dataset added more infomation to the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beecedf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: I need to open a checking account\n",
      "[{'generated_text': 'I need to open a checking account for this server. You can also use it with the following commands.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]\n",
      "Prompt: I want to apply for a credit card\n",
      "[{'generated_text': \"I want to apply for a credit card, but my first step is to apply for a MasterCard card.\\n\\n\\nI'm currently looking at a MasterCard card, but I'm not sure if the card can be used on my cards.\\nCheck out this list of 4 ways to get a MasterCard card.\\n1. Check out the Master Card with all your cards on it.\\n2. Check out the Master Card with all your cards on it.\\n3. Check out the Master Card with all your cards on it.\\nIf you want to use a MasterCard, it's much easier than using a MasterCard.\\n4. Test the Master Card with all your cards on it.\\n5. Get a MasterCard with all your cards on it.\\n6. Check out the Master Card with all your cards on it.\\nOnce you get a MasterCard, I'll add a MasterCard to the card.\\n7. Check out the Master Card with all your cards on it.\\nI've mentioned the Master Card and I'll cover it with this post.\\nI've written about some other ways to get a MasterCard to work so that I can make sure you're not reading too much.\\nI'm not sure if the MasterCard will be compatible with my\"}]\n",
      "Prompt: I want to transfer money to my savings account\n",
      "[{'generated_text': \"I want to transfer money to my savings account or that I can pay off my debt. And I want to keep that money and the benefits that it brings to my life.\\n\\n\\n\\nMy savings account is just one of the many ways I get back and forth between my parents, and I've been a great investor and a great investor for many years. I'm going to take advantage of it. I think that if I want to stay in the business and have that money invested in my life, I'm going to do just that.\\nHowever, I was also a great investor for many years until I was in high school and I've been a huge supporter of my life, and I'm ready to go back to the business in a way that I can't do without it.\\nMy parents have been so supportive and supportive for me that I've given my parents a huge amount of free time to go to the business.\\nBecause I've been the first black person to receive a government grant of $9,000 in federal subsidies, I was able to earn $9,000 in federal subsidies.\\nMy father-in-law, David, is the CEO of the company, and his wife, Sharon, is a member of the board of directors for the company.\\nI have three children\"}]\n",
      "Prompt: I need to setup automatic payments for my utilities\n",
      "[{'generated_text': \"I need to setup automatic payments for my utilities and the Internet.\\n\\nMy computer is running Linux. I'm using the WQI-DNS-DNS-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-\"}]\n"
     ]
    }
   ],
   "source": [
    "# For easy reference, below is what the original model results on the same prompts\n",
    "# repeated here\n",
    "for prompt in prompts:\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(orig_generator(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d448e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
