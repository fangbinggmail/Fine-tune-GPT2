{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 563,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017761989342806393,
      "grad_norm": 9.48119068145752,
      "learning_rate": 9.920071047957373e-06,
      "loss": 0.807,
      "step": 10
    },
    {
      "epoch": 0.035523978685612786,
      "grad_norm": 7.975127696990967,
      "learning_rate": 9.83126110124334e-06,
      "loss": 0.7843,
      "step": 20
    },
    {
      "epoch": 0.05328596802841918,
      "grad_norm": 2.164973258972168,
      "learning_rate": 9.742451154529307e-06,
      "loss": 0.7147,
      "step": 30
    },
    {
      "epoch": 0.07104795737122557,
      "grad_norm": 6.019589424133301,
      "learning_rate": 9.653641207815277e-06,
      "loss": 0.7374,
      "step": 40
    },
    {
      "epoch": 0.08880994671403197,
      "grad_norm": 3.3149571418762207,
      "learning_rate": 9.564831261101243e-06,
      "loss": 0.6836,
      "step": 50
    },
    {
      "epoch": 0.10657193605683836,
      "grad_norm": 1.7694298028945923,
      "learning_rate": 9.476021314387213e-06,
      "loss": 0.7144,
      "step": 60
    },
    {
      "epoch": 0.12433392539964476,
      "grad_norm": 1.732472538948059,
      "learning_rate": 9.38721136767318e-06,
      "loss": 0.7499,
      "step": 70
    },
    {
      "epoch": 0.14209591474245115,
      "grad_norm": 5.209467887878418,
      "learning_rate": 9.298401420959147e-06,
      "loss": 0.6734,
      "step": 80
    },
    {
      "epoch": 0.15985790408525755,
      "grad_norm": 6.780267238616943,
      "learning_rate": 9.209591474245117e-06,
      "loss": 0.6876,
      "step": 90
    },
    {
      "epoch": 0.17761989342806395,
      "grad_norm": 3.7342638969421387,
      "learning_rate": 9.120781527531083e-06,
      "loss": 0.6937,
      "step": 100
    },
    {
      "epoch": 0.19538188277087035,
      "grad_norm": 9.939770698547363,
      "learning_rate": 9.031971580817053e-06,
      "loss": 0.6957,
      "step": 110
    },
    {
      "epoch": 0.21314387211367672,
      "grad_norm": 4.647744655609131,
      "learning_rate": 8.943161634103021e-06,
      "loss": 0.7488,
      "step": 120
    },
    {
      "epoch": 0.23090586145648312,
      "grad_norm": 1.756168246269226,
      "learning_rate": 8.854351687388987e-06,
      "loss": 0.6931,
      "step": 130
    },
    {
      "epoch": 0.24866785079928952,
      "grad_norm": 1.4653416872024536,
      "learning_rate": 8.765541740674957e-06,
      "loss": 0.692,
      "step": 140
    },
    {
      "epoch": 0.2664298401420959,
      "grad_norm": 6.548004627227783,
      "learning_rate": 8.676731793960925e-06,
      "loss": 0.7256,
      "step": 150
    },
    {
      "epoch": 0.2841918294849023,
      "grad_norm": 2.9273881912231445,
      "learning_rate": 8.587921847246893e-06,
      "loss": 0.7358,
      "step": 160
    },
    {
      "epoch": 0.3019538188277087,
      "grad_norm": 4.625762939453125,
      "learning_rate": 8.499111900532861e-06,
      "loss": 0.7166,
      "step": 170
    },
    {
      "epoch": 0.3197158081705151,
      "grad_norm": 2.6031532287597656,
      "learning_rate": 8.410301953818827e-06,
      "loss": 0.7473,
      "step": 180
    },
    {
      "epoch": 0.33747779751332146,
      "grad_norm": 2.029768943786621,
      "learning_rate": 8.321492007104797e-06,
      "loss": 0.7051,
      "step": 190
    },
    {
      "epoch": 0.3552397868561279,
      "grad_norm": 3.7874088287353516,
      "learning_rate": 8.232682060390765e-06,
      "loss": 0.7087,
      "step": 200
    },
    {
      "epoch": 0.37300177619893427,
      "grad_norm": 1.974740982055664,
      "learning_rate": 8.143872113676733e-06,
      "loss": 0.6704,
      "step": 210
    },
    {
      "epoch": 0.3907637655417407,
      "grad_norm": 11.195808410644531,
      "learning_rate": 8.0550621669627e-06,
      "loss": 0.7165,
      "step": 220
    },
    {
      "epoch": 0.40852575488454707,
      "grad_norm": 6.3252949714660645,
      "learning_rate": 7.966252220248669e-06,
      "loss": 0.6884,
      "step": 230
    },
    {
      "epoch": 0.42628774422735344,
      "grad_norm": 2.822068214416504,
      "learning_rate": 7.877442273534637e-06,
      "loss": 0.7095,
      "step": 240
    },
    {
      "epoch": 0.44404973357015987,
      "grad_norm": 2.0990054607391357,
      "learning_rate": 7.788632326820605e-06,
      "loss": 0.7196,
      "step": 250
    },
    {
      "epoch": 0.46181172291296624,
      "grad_norm": 2.7920501232147217,
      "learning_rate": 7.699822380106573e-06,
      "loss": 0.7119,
      "step": 260
    },
    {
      "epoch": 0.47957371225577267,
      "grad_norm": 3.0202455520629883,
      "learning_rate": 7.611012433392541e-06,
      "loss": 0.712,
      "step": 270
    },
    {
      "epoch": 0.49733570159857904,
      "grad_norm": 3.4351892471313477,
      "learning_rate": 7.522202486678508e-06,
      "loss": 0.701,
      "step": 280
    },
    {
      "epoch": 0.5150976909413855,
      "grad_norm": 1.6714856624603271,
      "learning_rate": 7.433392539964477e-06,
      "loss": 0.6791,
      "step": 290
    },
    {
      "epoch": 0.5328596802841918,
      "grad_norm": 1.7521793842315674,
      "learning_rate": 7.344582593250445e-06,
      "loss": 0.6962,
      "step": 300
    },
    {
      "epoch": 0.5506216696269982,
      "grad_norm": 5.8280229568481445,
      "learning_rate": 7.255772646536413e-06,
      "loss": 0.6781,
      "step": 310
    },
    {
      "epoch": 0.5683836589698046,
      "grad_norm": 4.817876815795898,
      "learning_rate": 7.1669626998223805e-06,
      "loss": 0.6841,
      "step": 320
    },
    {
      "epoch": 0.5861456483126111,
      "grad_norm": 5.329799652099609,
      "learning_rate": 7.0781527531083485e-06,
      "loss": 0.7063,
      "step": 330
    },
    {
      "epoch": 0.6039076376554174,
      "grad_norm": 1.7027263641357422,
      "learning_rate": 6.989342806394317e-06,
      "loss": 0.6806,
      "step": 340
    },
    {
      "epoch": 0.6216696269982238,
      "grad_norm": 3.280947208404541,
      "learning_rate": 6.9005328596802845e-06,
      "loss": 0.6987,
      "step": 350
    },
    {
      "epoch": 0.6394316163410302,
      "grad_norm": 2.7919468879699707,
      "learning_rate": 6.811722912966253e-06,
      "loss": 0.6791,
      "step": 360
    },
    {
      "epoch": 0.6571936056838366,
      "grad_norm": 2.427929401397705,
      "learning_rate": 6.7229129662522204e-06,
      "loss": 0.6947,
      "step": 370
    },
    {
      "epoch": 0.6749555950266429,
      "grad_norm": 2.8764796257019043,
      "learning_rate": 6.634103019538188e-06,
      "loss": 0.6753,
      "step": 380
    },
    {
      "epoch": 0.6927175843694494,
      "grad_norm": 4.937638282775879,
      "learning_rate": 6.545293072824157e-06,
      "loss": 0.6836,
      "step": 390
    },
    {
      "epoch": 0.7104795737122558,
      "grad_norm": 5.160743236541748,
      "learning_rate": 6.456483126110124e-06,
      "loss": 0.6805,
      "step": 400
    },
    {
      "epoch": 0.7282415630550622,
      "grad_norm": 1.403759241104126,
      "learning_rate": 6.367673179396093e-06,
      "loss": 0.6909,
      "step": 410
    },
    {
      "epoch": 0.7460035523978685,
      "grad_norm": 3.709587335586548,
      "learning_rate": 6.278863232682061e-06,
      "loss": 0.6957,
      "step": 420
    },
    {
      "epoch": 0.7637655417406749,
      "grad_norm": 7.182733535766602,
      "learning_rate": 6.190053285968028e-06,
      "loss": 0.701,
      "step": 430
    },
    {
      "epoch": 0.7815275310834814,
      "grad_norm": 1.9292618036270142,
      "learning_rate": 6.101243339253997e-06,
      "loss": 0.6953,
      "step": 440
    },
    {
      "epoch": 0.7992895204262878,
      "grad_norm": 7.539717674255371,
      "learning_rate": 6.012433392539965e-06,
      "loss": 0.6739,
      "step": 450
    },
    {
      "epoch": 0.8170515097690941,
      "grad_norm": 2.025771141052246,
      "learning_rate": 5.923623445825933e-06,
      "loss": 0.6959,
      "step": 460
    },
    {
      "epoch": 0.8348134991119005,
      "grad_norm": 5.516820430755615,
      "learning_rate": 5.834813499111901e-06,
      "loss": 0.6973,
      "step": 470
    },
    {
      "epoch": 0.8525754884547069,
      "grad_norm": 2.2460877895355225,
      "learning_rate": 5.746003552397868e-06,
      "loss": 0.6895,
      "step": 480
    },
    {
      "epoch": 0.8703374777975134,
      "grad_norm": 3.0110418796539307,
      "learning_rate": 5.657193605683837e-06,
      "loss": 0.6999,
      "step": 490
    },
    {
      "epoch": 0.8880994671403197,
      "grad_norm": 1.5504647493362427,
      "learning_rate": 5.568383658969805e-06,
      "loss": 0.6815,
      "step": 500
    },
    {
      "epoch": 0.9058614564831261,
      "grad_norm": 1.7077523469924927,
      "learning_rate": 5.479573712255774e-06,
      "loss": 0.6888,
      "step": 510
    },
    {
      "epoch": 0.9236234458259325,
      "grad_norm": 1.755784511566162,
      "learning_rate": 5.390763765541741e-06,
      "loss": 0.6768,
      "step": 520
    },
    {
      "epoch": 0.9413854351687388,
      "grad_norm": 7.49265193939209,
      "learning_rate": 5.301953818827709e-06,
      "loss": 0.6957,
      "step": 530
    },
    {
      "epoch": 0.9591474245115453,
      "grad_norm": 2.0259945392608643,
      "learning_rate": 5.213143872113677e-06,
      "loss": 0.6773,
      "step": 540
    },
    {
      "epoch": 0.9769094138543517,
      "grad_norm": 2.37546443939209,
      "learning_rate": 5.124333925399645e-06,
      "loss": 0.682,
      "step": 550
    },
    {
      "epoch": 0.9946714031971581,
      "grad_norm": 4.803752899169922,
      "learning_rate": 5.035523978685614e-06,
      "loss": 0.6891,
      "step": 560
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.574,
      "eval_loss": 0.6841139197349548,
      "eval_model_preparation_time": 0.0029,
      "eval_runtime": 93.2653,
      "eval_samples_per_second": 5.361,
      "eval_steps_per_second": 0.675,
      "step": 563
    }
  ],
  "logging_steps": 10,
  "max_steps": 1126,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1048108591789440.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
