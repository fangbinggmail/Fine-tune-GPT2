{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1689,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017761989342806393,
      "grad_norm": 0.1887463629245758,
      "learning_rate": 9.946714031971581e-06,
      "loss": 0.6997,
      "step": 10
    },
    {
      "epoch": 0.035523978685612786,
      "grad_norm": 0.17676690220832825,
      "learning_rate": 9.887507400828893e-06,
      "loss": 0.7005,
      "step": 20
    },
    {
      "epoch": 0.05328596802841918,
      "grad_norm": 0.11218015849590302,
      "learning_rate": 9.828300769686205e-06,
      "loss": 0.6817,
      "step": 30
    },
    {
      "epoch": 0.07104795737122557,
      "grad_norm": 0.15226392447948456,
      "learning_rate": 9.769094138543517e-06,
      "loss": 0.7059,
      "step": 40
    },
    {
      "epoch": 0.08880994671403197,
      "grad_norm": 0.16412198543548584,
      "learning_rate": 9.70988750740083e-06,
      "loss": 0.7075,
      "step": 50
    },
    {
      "epoch": 0.10657193605683836,
      "grad_norm": 0.0927145704627037,
      "learning_rate": 9.650680876258141e-06,
      "loss": 0.709,
      "step": 60
    },
    {
      "epoch": 0.12433392539964476,
      "grad_norm": 0.1487920880317688,
      "learning_rate": 9.591474245115455e-06,
      "loss": 0.7148,
      "step": 70
    },
    {
      "epoch": 0.14209591474245115,
      "grad_norm": 0.10333824902772903,
      "learning_rate": 9.532267613972765e-06,
      "loss": 0.6933,
      "step": 80
    },
    {
      "epoch": 0.15985790408525755,
      "grad_norm": 0.10934535413980484,
      "learning_rate": 9.473060982830077e-06,
      "loss": 0.6766,
      "step": 90
    },
    {
      "epoch": 0.17761989342806395,
      "grad_norm": 0.09704507887363434,
      "learning_rate": 9.413854351687389e-06,
      "loss": 0.696,
      "step": 100
    },
    {
      "epoch": 0.19538188277087035,
      "grad_norm": 0.09138362109661102,
      "learning_rate": 9.354647720544701e-06,
      "loss": 0.6971,
      "step": 110
    },
    {
      "epoch": 0.21314387211367672,
      "grad_norm": 0.15194551646709442,
      "learning_rate": 9.295441089402015e-06,
      "loss": 0.6899,
      "step": 120
    },
    {
      "epoch": 0.23090586145648312,
      "grad_norm": 0.17917224764823914,
      "learning_rate": 9.236234458259325e-06,
      "loss": 0.7022,
      "step": 130
    },
    {
      "epoch": 0.24866785079928952,
      "grad_norm": 0.1403929740190506,
      "learning_rate": 9.177027827116639e-06,
      "loss": 0.6819,
      "step": 140
    },
    {
      "epoch": 0.2664298401420959,
      "grad_norm": 0.16509069502353668,
      "learning_rate": 9.117821195973949e-06,
      "loss": 0.7137,
      "step": 150
    },
    {
      "epoch": 0.2841918294849023,
      "grad_norm": 0.11191622167825699,
      "learning_rate": 9.058614564831261e-06,
      "loss": 0.7024,
      "step": 160
    },
    {
      "epoch": 0.3019538188277087,
      "grad_norm": 0.1980636566877365,
      "learning_rate": 8.999407933688575e-06,
      "loss": 0.6964,
      "step": 170
    },
    {
      "epoch": 0.3197158081705151,
      "grad_norm": 0.15830503404140472,
      "learning_rate": 8.940201302545885e-06,
      "loss": 0.6853,
      "step": 180
    },
    {
      "epoch": 0.33747779751332146,
      "grad_norm": 0.21563878655433655,
      "learning_rate": 8.880994671403199e-06,
      "loss": 0.6956,
      "step": 190
    },
    {
      "epoch": 0.3552397868561279,
      "grad_norm": 0.10221321135759354,
      "learning_rate": 8.821788040260509e-06,
      "loss": 0.6921,
      "step": 200
    },
    {
      "epoch": 0.37300177619893427,
      "grad_norm": 0.12962979078292847,
      "learning_rate": 8.762581409117823e-06,
      "loss": 0.685,
      "step": 210
    },
    {
      "epoch": 0.3907637655417407,
      "grad_norm": 0.10767096281051636,
      "learning_rate": 8.703374777975135e-06,
      "loss": 0.7016,
      "step": 220
    },
    {
      "epoch": 0.40852575488454707,
      "grad_norm": 0.20919981598854065,
      "learning_rate": 8.644168146832445e-06,
      "loss": 0.6915,
      "step": 230
    },
    {
      "epoch": 0.42628774422735344,
      "grad_norm": 0.08564873039722443,
      "learning_rate": 8.584961515689759e-06,
      "loss": 0.6833,
      "step": 240
    },
    {
      "epoch": 0.44404973357015987,
      "grad_norm": 0.12874865531921387,
      "learning_rate": 8.525754884547069e-06,
      "loss": 0.7052,
      "step": 250
    },
    {
      "epoch": 0.46181172291296624,
      "grad_norm": 0.10013006627559662,
      "learning_rate": 8.466548253404383e-06,
      "loss": 0.6883,
      "step": 260
    },
    {
      "epoch": 0.47957371225577267,
      "grad_norm": 0.09727214276790619,
      "learning_rate": 8.407341622261695e-06,
      "loss": 0.6941,
      "step": 270
    },
    {
      "epoch": 0.49733570159857904,
      "grad_norm": 0.33978182077407837,
      "learning_rate": 8.348134991119005e-06,
      "loss": 0.7204,
      "step": 280
    },
    {
      "epoch": 0.5150976909413855,
      "grad_norm": 0.16481533646583557,
      "learning_rate": 8.288928359976319e-06,
      "loss": 0.6808,
      "step": 290
    },
    {
      "epoch": 0.5328596802841918,
      "grad_norm": 0.14067120850086212,
      "learning_rate": 8.229721728833629e-06,
      "loss": 0.7045,
      "step": 300
    },
    {
      "epoch": 0.5506216696269982,
      "grad_norm": 0.11525290459394455,
      "learning_rate": 8.170515097690943e-06,
      "loss": 0.6786,
      "step": 310
    },
    {
      "epoch": 0.5683836589698046,
      "grad_norm": 0.23210549354553223,
      "learning_rate": 8.111308466548255e-06,
      "loss": 0.7019,
      "step": 320
    },
    {
      "epoch": 0.5861456483126111,
      "grad_norm": 0.1762879639863968,
      "learning_rate": 8.052101835405567e-06,
      "loss": 0.6906,
      "step": 330
    },
    {
      "epoch": 0.6039076376554174,
      "grad_norm": 0.22827120125293732,
      "learning_rate": 7.992895204262878e-06,
      "loss": 0.6843,
      "step": 340
    },
    {
      "epoch": 0.6216696269982238,
      "grad_norm": 0.192154660820961,
      "learning_rate": 7.933688573120189e-06,
      "loss": 0.6783,
      "step": 350
    },
    {
      "epoch": 0.6394316163410302,
      "grad_norm": 0.16766420006752014,
      "learning_rate": 7.874481941977502e-06,
      "loss": 0.6815,
      "step": 360
    },
    {
      "epoch": 0.6571936056838366,
      "grad_norm": 0.14179512858390808,
      "learning_rate": 7.815275310834814e-06,
      "loss": 0.6889,
      "step": 370
    },
    {
      "epoch": 0.6749555950266429,
      "grad_norm": 0.11835943907499313,
      "learning_rate": 7.756068679692126e-06,
      "loss": 0.7068,
      "step": 380
    },
    {
      "epoch": 0.6927175843694494,
      "grad_norm": 0.13377055525779724,
      "learning_rate": 7.696862048549438e-06,
      "loss": 0.696,
      "step": 390
    },
    {
      "epoch": 0.7104795737122558,
      "grad_norm": 0.1022186204791069,
      "learning_rate": 7.63765541740675e-06,
      "loss": 0.704,
      "step": 400
    },
    {
      "epoch": 0.7282415630550622,
      "grad_norm": 0.11359334737062454,
      "learning_rate": 7.578448786264062e-06,
      "loss": 0.6986,
      "step": 410
    },
    {
      "epoch": 0.7460035523978685,
      "grad_norm": 0.14084766805171967,
      "learning_rate": 7.519242155121374e-06,
      "loss": 0.6799,
      "step": 420
    },
    {
      "epoch": 0.7637655417406749,
      "grad_norm": 0.16424624621868134,
      "learning_rate": 7.4600355239786855e-06,
      "loss": 0.6944,
      "step": 430
    },
    {
      "epoch": 0.7815275310834814,
      "grad_norm": 0.12808498740196228,
      "learning_rate": 7.400828892835998e-06,
      "loss": 0.6889,
      "step": 440
    },
    {
      "epoch": 0.7992895204262878,
      "grad_norm": 0.2241271287202835,
      "learning_rate": 7.3416222616933095e-06,
      "loss": 0.6895,
      "step": 450
    },
    {
      "epoch": 0.8170515097690941,
      "grad_norm": 0.10943222045898438,
      "learning_rate": 7.282415630550622e-06,
      "loss": 0.7016,
      "step": 460
    },
    {
      "epoch": 0.8348134991119005,
      "grad_norm": 0.11350490897893906,
      "learning_rate": 7.223208999407934e-06,
      "loss": 0.7064,
      "step": 470
    },
    {
      "epoch": 0.8525754884547069,
      "grad_norm": 0.20237289369106293,
      "learning_rate": 7.164002368265246e-06,
      "loss": 0.6794,
      "step": 480
    },
    {
      "epoch": 0.8703374777975134,
      "grad_norm": 0.21847407519817352,
      "learning_rate": 7.104795737122558e-06,
      "loss": 0.6862,
      "step": 490
    },
    {
      "epoch": 0.8880994671403197,
      "grad_norm": 0.1304604858160019,
      "learning_rate": 7.0455891059798694e-06,
      "loss": 0.7055,
      "step": 500
    },
    {
      "epoch": 0.9058614564831261,
      "grad_norm": 0.1672908067703247,
      "learning_rate": 6.986382474837182e-06,
      "loss": 0.6959,
      "step": 510
    },
    {
      "epoch": 0.9236234458259325,
      "grad_norm": 0.14619091153144836,
      "learning_rate": 6.927175843694495e-06,
      "loss": 0.6748,
      "step": 520
    },
    {
      "epoch": 0.9413854351687388,
      "grad_norm": 0.13246959447860718,
      "learning_rate": 6.867969212551806e-06,
      "loss": 0.6763,
      "step": 530
    },
    {
      "epoch": 0.9591474245115453,
      "grad_norm": 0.23408100008964539,
      "learning_rate": 6.808762581409118e-06,
      "loss": 0.6982,
      "step": 540
    },
    {
      "epoch": 0.9769094138543517,
      "grad_norm": 0.16396094858646393,
      "learning_rate": 6.74955595026643e-06,
      "loss": 0.6899,
      "step": 550
    },
    {
      "epoch": 0.9946714031971581,
      "grad_norm": 0.10718334466218948,
      "learning_rate": 6.690349319123742e-06,
      "loss": 0.6946,
      "step": 560
    },
    {
      "epoch": 1.0,
      "eval_runtime": 95.9548,
      "eval_samples_per_second": 5.211,
      "eval_steps_per_second": 0.657,
      "step": 563
    },
    {
      "epoch": 1.0124333925399644,
      "grad_norm": 0.11933977156877518,
      "learning_rate": 6.631142687981055e-06,
      "loss": 0.6862,
      "step": 570
    },
    {
      "epoch": 1.030195381882771,
      "grad_norm": 0.11842503398656845,
      "learning_rate": 6.571936056838366e-06,
      "loss": 0.7047,
      "step": 580
    },
    {
      "epoch": 1.0479573712255772,
      "grad_norm": 0.24543675780296326,
      "learning_rate": 6.512729425695678e-06,
      "loss": 0.7073,
      "step": 590
    },
    {
      "epoch": 1.0657193605683837,
      "grad_norm": 0.10021346062421799,
      "learning_rate": 6.45352279455299e-06,
      "loss": 0.7034,
      "step": 600
    },
    {
      "epoch": 1.0834813499111902,
      "grad_norm": 0.34217381477355957,
      "learning_rate": 6.394316163410302e-06,
      "loss": 0.6994,
      "step": 610
    },
    {
      "epoch": 1.1012433392539964,
      "grad_norm": 0.3079529404640198,
      "learning_rate": 6.335109532267615e-06,
      "loss": 0.7038,
      "step": 620
    },
    {
      "epoch": 1.119005328596803,
      "grad_norm": 0.10850554704666138,
      "learning_rate": 6.275902901124926e-06,
      "loss": 0.6877,
      "step": 630
    },
    {
      "epoch": 1.1367673179396092,
      "grad_norm": 0.2286878228187561,
      "learning_rate": 6.216696269982239e-06,
      "loss": 0.6894,
      "step": 640
    },
    {
      "epoch": 1.1545293072824157,
      "grad_norm": 0.20606407523155212,
      "learning_rate": 6.157489638839551e-06,
      "loss": 0.6685,
      "step": 650
    },
    {
      "epoch": 1.1722912966252221,
      "grad_norm": 0.10632332414388657,
      "learning_rate": 6.098283007696862e-06,
      "loss": 0.6992,
      "step": 660
    },
    {
      "epoch": 1.1900532859680284,
      "grad_norm": 0.15824516117572784,
      "learning_rate": 6.039076376554175e-06,
      "loss": 0.6895,
      "step": 670
    },
    {
      "epoch": 1.2078152753108349,
      "grad_norm": 0.12523974478244781,
      "learning_rate": 5.979869745411486e-06,
      "loss": 0.6818,
      "step": 680
    },
    {
      "epoch": 1.2255772646536411,
      "grad_norm": 0.14113985002040863,
      "learning_rate": 5.920663114268799e-06,
      "loss": 0.7001,
      "step": 690
    },
    {
      "epoch": 1.2433392539964476,
      "grad_norm": 0.12846815586090088,
      "learning_rate": 5.861456483126111e-06,
      "loss": 0.7101,
      "step": 700
    },
    {
      "epoch": 1.261101243339254,
      "grad_norm": 0.2965729534626007,
      "learning_rate": 5.802249851983423e-06,
      "loss": 0.6859,
      "step": 710
    },
    {
      "epoch": 1.2788632326820604,
      "grad_norm": 0.1272626370191574,
      "learning_rate": 5.743043220840735e-06,
      "loss": 0.7056,
      "step": 720
    },
    {
      "epoch": 1.2966252220248669,
      "grad_norm": 0.15143820643424988,
      "learning_rate": 5.683836589698046e-06,
      "loss": 0.691,
      "step": 730
    },
    {
      "epoch": 1.3143872113676731,
      "grad_norm": 0.12665678560733795,
      "learning_rate": 5.624629958555359e-06,
      "loss": 0.6886,
      "step": 740
    },
    {
      "epoch": 1.3321492007104796,
      "grad_norm": 0.20713596045970917,
      "learning_rate": 5.565423327412672e-06,
      "loss": 0.6969,
      "step": 750
    },
    {
      "epoch": 1.349911190053286,
      "grad_norm": 0.33936843276023865,
      "learning_rate": 5.506216696269983e-06,
      "loss": 0.672,
      "step": 760
    },
    {
      "epoch": 1.3676731793960923,
      "grad_norm": 0.1526985615491867,
      "learning_rate": 5.447010065127295e-06,
      "loss": 0.684,
      "step": 770
    },
    {
      "epoch": 1.3854351687388988,
      "grad_norm": 0.10579230636358261,
      "learning_rate": 5.387803433984607e-06,
      "loss": 0.6889,
      "step": 780
    },
    {
      "epoch": 1.403197158081705,
      "grad_norm": 0.11848238855600357,
      "learning_rate": 5.328596802841919e-06,
      "loss": 0.6984,
      "step": 790
    },
    {
      "epoch": 1.4209591474245116,
      "grad_norm": 0.3234933316707611,
      "learning_rate": 5.2693901716992316e-06,
      "loss": 0.6908,
      "step": 800
    },
    {
      "epoch": 1.438721136767318,
      "grad_norm": 0.137676402926445,
      "learning_rate": 5.210183540556543e-06,
      "loss": 0.7014,
      "step": 810
    },
    {
      "epoch": 1.4564831261101243,
      "grad_norm": 0.17156106233596802,
      "learning_rate": 5.150976909413855e-06,
      "loss": 0.6994,
      "step": 820
    },
    {
      "epoch": 1.4742451154529308,
      "grad_norm": 0.11470119655132294,
      "learning_rate": 5.091770278271167e-06,
      "loss": 0.6914,
      "step": 830
    },
    {
      "epoch": 1.492007104795737,
      "grad_norm": 0.09990663081407547,
      "learning_rate": 5.032563647128479e-06,
      "loss": 0.7024,
      "step": 840
    },
    {
      "epoch": 1.5097690941385435,
      "grad_norm": 0.18056905269622803,
      "learning_rate": 4.973357015985791e-06,
      "loss": 0.6951,
      "step": 850
    },
    {
      "epoch": 1.52753108348135,
      "grad_norm": 0.08176574110984802,
      "learning_rate": 4.914150384843103e-06,
      "loss": 0.6731,
      "step": 860
    },
    {
      "epoch": 1.5452930728241563,
      "grad_norm": 0.11680003255605698,
      "learning_rate": 4.854943753700415e-06,
      "loss": 0.7011,
      "step": 870
    },
    {
      "epoch": 1.5630550621669625,
      "grad_norm": 0.14213259518146515,
      "learning_rate": 4.7957371225577274e-06,
      "loss": 0.6954,
      "step": 880
    },
    {
      "epoch": 1.580817051509769,
      "grad_norm": 0.17748598754405975,
      "learning_rate": 4.736530491415039e-06,
      "loss": 0.6927,
      "step": 890
    },
    {
      "epoch": 1.5985790408525755,
      "grad_norm": 0.09514344483613968,
      "learning_rate": 4.6773238602723506e-06,
      "loss": 0.6876,
      "step": 900
    },
    {
      "epoch": 1.616341030195382,
      "grad_norm": 0.15670499205589294,
      "learning_rate": 4.6181172291296625e-06,
      "loss": 0.7059,
      "step": 910
    },
    {
      "epoch": 1.6341030195381883,
      "grad_norm": 0.13738790154457092,
      "learning_rate": 4.5589105979869745e-06,
      "loss": 0.7121,
      "step": 920
    },
    {
      "epoch": 1.6518650088809945,
      "grad_norm": 0.13923870027065277,
      "learning_rate": 4.499703966844287e-06,
      "loss": 0.71,
      "step": 930
    },
    {
      "epoch": 1.669626998223801,
      "grad_norm": 0.14512190222740173,
      "learning_rate": 4.440497335701599e-06,
      "loss": 0.7044,
      "step": 940
    },
    {
      "epoch": 1.6873889875666075,
      "grad_norm": 0.10579102486371994,
      "learning_rate": 4.381290704558911e-06,
      "loss": 0.6959,
      "step": 950
    },
    {
      "epoch": 1.705150976909414,
      "grad_norm": 0.23703111708164215,
      "learning_rate": 4.3220840734162225e-06,
      "loss": 0.6911,
      "step": 960
    },
    {
      "epoch": 1.7229129662522202,
      "grad_norm": 0.09833335131406784,
      "learning_rate": 4.2628774422735345e-06,
      "loss": 0.7021,
      "step": 970
    },
    {
      "epoch": 1.7406749555950265,
      "grad_norm": 0.13516835868358612,
      "learning_rate": 4.203670811130847e-06,
      "loss": 0.6968,
      "step": 980
    },
    {
      "epoch": 1.758436944937833,
      "grad_norm": 0.14405779540538788,
      "learning_rate": 4.144464179988159e-06,
      "loss": 0.6814,
      "step": 990
    },
    {
      "epoch": 1.7761989342806395,
      "grad_norm": 0.12526710331439972,
      "learning_rate": 4.085257548845471e-06,
      "loss": 0.6851,
      "step": 1000
    },
    {
      "epoch": 1.793960923623446,
      "grad_norm": 0.12055040895938873,
      "learning_rate": 4.026050917702783e-06,
      "loss": 0.6755,
      "step": 1010
    },
    {
      "epoch": 1.8117229129662522,
      "grad_norm": 0.10400662571191788,
      "learning_rate": 3.966844286560094e-06,
      "loss": 0.6739,
      "step": 1020
    },
    {
      "epoch": 1.8294849023090585,
      "grad_norm": 0.31241703033447266,
      "learning_rate": 3.907637655417407e-06,
      "loss": 0.6673,
      "step": 1030
    },
    {
      "epoch": 1.847246891651865,
      "grad_norm": 0.10812843590974808,
      "learning_rate": 3.848431024274719e-06,
      "loss": 0.6897,
      "step": 1040
    },
    {
      "epoch": 1.8650088809946714,
      "grad_norm": 0.11804443597793579,
      "learning_rate": 3.789224393132031e-06,
      "loss": 0.6979,
      "step": 1050
    },
    {
      "epoch": 1.882770870337478,
      "grad_norm": 0.140244722366333,
      "learning_rate": 3.7300177619893428e-06,
      "loss": 0.6862,
      "step": 1060
    },
    {
      "epoch": 1.9005328596802842,
      "grad_norm": 0.2155281901359558,
      "learning_rate": 3.6708111308466547e-06,
      "loss": 0.6999,
      "step": 1070
    },
    {
      "epoch": 1.9182948490230904,
      "grad_norm": 0.15711309015750885,
      "learning_rate": 3.611604499703967e-06,
      "loss": 0.6793,
      "step": 1080
    },
    {
      "epoch": 1.936056838365897,
      "grad_norm": 0.14854463934898376,
      "learning_rate": 3.552397868561279e-06,
      "loss": 0.6935,
      "step": 1090
    },
    {
      "epoch": 1.9538188277087034,
      "grad_norm": 0.12007877975702286,
      "learning_rate": 3.493191237418591e-06,
      "loss": 0.6795,
      "step": 1100
    },
    {
      "epoch": 1.97158081705151,
      "grad_norm": 0.14460857212543488,
      "learning_rate": 3.433984606275903e-06,
      "loss": 0.695,
      "step": 1110
    },
    {
      "epoch": 1.9893428063943162,
      "grad_norm": 0.23015187680721283,
      "learning_rate": 3.374777975133215e-06,
      "loss": 0.6935,
      "step": 1120
    },
    {
      "epoch": 2.0,
      "eval_runtime": 95.5246,
      "eval_samples_per_second": 5.234,
      "eval_steps_per_second": 0.66,
      "step": 1126
    },
    {
      "epoch": 2.0071047957371224,
      "grad_norm": 0.1299932301044464,
      "learning_rate": 3.3155713439905275e-06,
      "loss": 0.7012,
      "step": 1130
    },
    {
      "epoch": 2.024866785079929,
      "grad_norm": 0.10609055310487747,
      "learning_rate": 3.256364712847839e-06,
      "loss": 0.6838,
      "step": 1140
    },
    {
      "epoch": 2.0426287744227354,
      "grad_norm": 0.2440616339445114,
      "learning_rate": 3.197158081705151e-06,
      "loss": 0.6597,
      "step": 1150
    },
    {
      "epoch": 2.060390763765542,
      "grad_norm": 0.34912458062171936,
      "learning_rate": 3.137951450562463e-06,
      "loss": 0.6934,
      "step": 1160
    },
    {
      "epoch": 2.0781527531083483,
      "grad_norm": 0.11046899855136871,
      "learning_rate": 3.0787448194197755e-06,
      "loss": 0.6825,
      "step": 1170
    },
    {
      "epoch": 2.0959147424511544,
      "grad_norm": 0.20780441164970398,
      "learning_rate": 3.0195381882770874e-06,
      "loss": 0.6844,
      "step": 1180
    },
    {
      "epoch": 2.113676731793961,
      "grad_norm": 0.1625109761953354,
      "learning_rate": 2.9603315571343994e-06,
      "loss": 0.6735,
      "step": 1190
    },
    {
      "epoch": 2.1314387211367674,
      "grad_norm": 0.18041785061359406,
      "learning_rate": 2.9011249259917114e-06,
      "loss": 0.6787,
      "step": 1200
    },
    {
      "epoch": 2.149200710479574,
      "grad_norm": 0.22086475789546967,
      "learning_rate": 2.841918294849023e-06,
      "loss": 0.6877,
      "step": 1210
    },
    {
      "epoch": 2.1669626998223803,
      "grad_norm": 0.11227750033140182,
      "learning_rate": 2.782711663706336e-06,
      "loss": 0.6856,
      "step": 1220
    },
    {
      "epoch": 2.1847246891651864,
      "grad_norm": 0.13735032081604004,
      "learning_rate": 2.7235050325636474e-06,
      "loss": 0.6948,
      "step": 1230
    },
    {
      "epoch": 2.202486678507993,
      "grad_norm": 0.18601395189762115,
      "learning_rate": 2.6642984014209594e-06,
      "loss": 0.6744,
      "step": 1240
    },
    {
      "epoch": 2.2202486678507993,
      "grad_norm": 0.15015488862991333,
      "learning_rate": 2.6050917702782713e-06,
      "loss": 0.6919,
      "step": 1250
    },
    {
      "epoch": 2.238010657193606,
      "grad_norm": 0.48161453008651733,
      "learning_rate": 2.5458851391355833e-06,
      "loss": 0.6819,
      "step": 1260
    },
    {
      "epoch": 2.2557726465364123,
      "grad_norm": 0.1980566829442978,
      "learning_rate": 2.4866785079928953e-06,
      "loss": 0.6878,
      "step": 1270
    },
    {
      "epoch": 2.2735346358792183,
      "grad_norm": 0.15379208326339722,
      "learning_rate": 2.4274718768502073e-06,
      "loss": 0.6925,
      "step": 1280
    },
    {
      "epoch": 2.291296625222025,
      "grad_norm": 0.11456692963838577,
      "learning_rate": 2.3682652457075193e-06,
      "loss": 0.6752,
      "step": 1290
    },
    {
      "epoch": 2.3090586145648313,
      "grad_norm": 0.13046951591968536,
      "learning_rate": 2.3090586145648313e-06,
      "loss": 0.7084,
      "step": 1300
    },
    {
      "epoch": 2.326820603907638,
      "grad_norm": 0.11813141405582428,
      "learning_rate": 2.2498519834221437e-06,
      "loss": 0.6897,
      "step": 1310
    },
    {
      "epoch": 2.3445825932504443,
      "grad_norm": 0.11792539805173874,
      "learning_rate": 2.1906453522794557e-06,
      "loss": 0.6778,
      "step": 1320
    },
    {
      "epoch": 2.3623445825932503,
      "grad_norm": 0.30266234278678894,
      "learning_rate": 2.1314387211367672e-06,
      "loss": 0.6675,
      "step": 1330
    },
    {
      "epoch": 2.380106571936057,
      "grad_norm": 0.1573459655046463,
      "learning_rate": 2.0722320899940796e-06,
      "loss": 0.7169,
      "step": 1340
    },
    {
      "epoch": 2.3978685612788633,
      "grad_norm": 0.21003654599189758,
      "learning_rate": 2.0130254588513916e-06,
      "loss": 0.692,
      "step": 1350
    },
    {
      "epoch": 2.4156305506216698,
      "grad_norm": 0.21728895604610443,
      "learning_rate": 1.9538188277087036e-06,
      "loss": 0.7025,
      "step": 1360
    },
    {
      "epoch": 2.4333925399644762,
      "grad_norm": 0.2902064323425293,
      "learning_rate": 1.8946121965660156e-06,
      "loss": 0.6913,
      "step": 1370
    },
    {
      "epoch": 2.4511545293072823,
      "grad_norm": 0.13737526535987854,
      "learning_rate": 1.8354055654233274e-06,
      "loss": 0.6845,
      "step": 1380
    },
    {
      "epoch": 2.4689165186500888,
      "grad_norm": 0.1498371660709381,
      "learning_rate": 1.7761989342806396e-06,
      "loss": 0.6922,
      "step": 1390
    },
    {
      "epoch": 2.4866785079928952,
      "grad_norm": 0.1489647775888443,
      "learning_rate": 1.7169923031379516e-06,
      "loss": 0.6748,
      "step": 1400
    },
    {
      "epoch": 2.5044404973357017,
      "grad_norm": 0.21671050786972046,
      "learning_rate": 1.6577856719952638e-06,
      "loss": 0.6908,
      "step": 1410
    },
    {
      "epoch": 2.522202486678508,
      "grad_norm": 0.12924891710281372,
      "learning_rate": 1.5985790408525755e-06,
      "loss": 0.7188,
      "step": 1420
    },
    {
      "epoch": 2.5399644760213143,
      "grad_norm": 0.13885532319545746,
      "learning_rate": 1.5393724097098877e-06,
      "loss": 0.7031,
      "step": 1430
    },
    {
      "epoch": 2.5577264653641207,
      "grad_norm": 0.10870567709207535,
      "learning_rate": 1.4801657785671997e-06,
      "loss": 0.6717,
      "step": 1440
    },
    {
      "epoch": 2.575488454706927,
      "grad_norm": 0.28728505969047546,
      "learning_rate": 1.4209591474245115e-06,
      "loss": 0.7043,
      "step": 1450
    },
    {
      "epoch": 2.5932504440497337,
      "grad_norm": 0.21379846334457397,
      "learning_rate": 1.3617525162818237e-06,
      "loss": 0.6754,
      "step": 1460
    },
    {
      "epoch": 2.61101243339254,
      "grad_norm": 0.19848281145095825,
      "learning_rate": 1.3025458851391357e-06,
      "loss": 0.676,
      "step": 1470
    },
    {
      "epoch": 2.6287744227353462,
      "grad_norm": 0.11881746351718903,
      "learning_rate": 1.2433392539964477e-06,
      "loss": 0.6958,
      "step": 1480
    },
    {
      "epoch": 2.6465364120781527,
      "grad_norm": 0.13361753523349762,
      "learning_rate": 1.1841326228537596e-06,
      "loss": 0.6833,
      "step": 1490
    },
    {
      "epoch": 2.664298401420959,
      "grad_norm": 0.23013001680374146,
      "learning_rate": 1.1249259917110718e-06,
      "loss": 0.7042,
      "step": 1500
    },
    {
      "epoch": 2.6820603907637657,
      "grad_norm": 0.14147791266441345,
      "learning_rate": 1.0657193605683836e-06,
      "loss": 0.686,
      "step": 1510
    },
    {
      "epoch": 2.699822380106572,
      "grad_norm": 0.3418489098548889,
      "learning_rate": 1.0065127294256958e-06,
      "loss": 0.6952,
      "step": 1520
    },
    {
      "epoch": 2.717584369449378,
      "grad_norm": 0.12425129860639572,
      "learning_rate": 9.473060982830078e-07,
      "loss": 0.6875,
      "step": 1530
    },
    {
      "epoch": 2.7353463587921847,
      "grad_norm": 0.2811794877052307,
      "learning_rate": 8.880994671403198e-07,
      "loss": 0.7039,
      "step": 1540
    },
    {
      "epoch": 2.753108348134991,
      "grad_norm": 0.11877251416444778,
      "learning_rate": 8.288928359976319e-07,
      "loss": 0.7125,
      "step": 1550
    },
    {
      "epoch": 2.7708703374777977,
      "grad_norm": 0.16862203180789948,
      "learning_rate": 7.696862048549439e-07,
      "loss": 0.6924,
      "step": 1560
    },
    {
      "epoch": 2.788632326820604,
      "grad_norm": 0.13795992732048035,
      "learning_rate": 7.104795737122557e-07,
      "loss": 0.696,
      "step": 1570
    },
    {
      "epoch": 2.80639431616341,
      "grad_norm": 0.12024232000112534,
      "learning_rate": 6.512729425695678e-07,
      "loss": 0.6904,
      "step": 1580
    },
    {
      "epoch": 2.8241563055062167,
      "grad_norm": 0.11294376850128174,
      "learning_rate": 5.920663114268798e-07,
      "loss": 0.6922,
      "step": 1590
    },
    {
      "epoch": 2.841918294849023,
      "grad_norm": 0.1651269793510437,
      "learning_rate": 5.328596802841918e-07,
      "loss": 0.6921,
      "step": 1600
    },
    {
      "epoch": 2.8596802841918296,
      "grad_norm": 0.32452720403671265,
      "learning_rate": 4.736530491415039e-07,
      "loss": 0.6796,
      "step": 1610
    },
    {
      "epoch": 2.877442273534636,
      "grad_norm": 0.16479459404945374,
      "learning_rate": 4.1444641799881594e-07,
      "loss": 0.6913,
      "step": 1620
    },
    {
      "epoch": 2.895204262877442,
      "grad_norm": 0.25989171862602234,
      "learning_rate": 3.5523978685612787e-07,
      "loss": 0.6814,
      "step": 1630
    },
    {
      "epoch": 2.9129662522202486,
      "grad_norm": 0.13917770981788635,
      "learning_rate": 2.960331557134399e-07,
      "loss": 0.6942,
      "step": 1640
    },
    {
      "epoch": 2.930728241563055,
      "grad_norm": 0.13179519772529602,
      "learning_rate": 2.3682652457075195e-07,
      "loss": 0.6995,
      "step": 1650
    },
    {
      "epoch": 2.9484902309058616,
      "grad_norm": 0.12996771931648254,
      "learning_rate": 1.7761989342806394e-07,
      "loss": 0.6943,
      "step": 1660
    },
    {
      "epoch": 2.966252220248668,
      "grad_norm": 0.12292252480983734,
      "learning_rate": 1.1841326228537598e-07,
      "loss": 0.6912,
      "step": 1670
    },
    {
      "epoch": 2.984014209591474,
      "grad_norm": 0.09654103219509125,
      "learning_rate": 5.920663114268799e-08,
      "loss": 0.6961,
      "step": 1680
    },
    {
      "epoch": 3.0,
      "eval_runtime": 94.7404,
      "eval_samples_per_second": 5.278,
      "eval_steps_per_second": 0.665,
      "step": 1689
    }
  ],
  "logging_steps": 10,
  "max_steps": 1689,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3173505267118560.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
